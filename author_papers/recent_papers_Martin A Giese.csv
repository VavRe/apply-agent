"title","year","venue","authors","type","url","abstract"
"CLIP-Branches:  Interactive Fine-Tuning for Text-Image Retrieval.","2024","SIGIR","Christian Lülf, Denis Mayr Lima Martins, Marcos Antonio Vaz Salles, Yongluan Zhou, Fabian Gieseke","Conference and Workshop Papers","https://dblp.org/rec/conf/sigir/LulfMSZG24","The advent of text-image models, most notably CLIP, has significantly transformed the landscape of information retrieval. These models enable the fusion of various modalities, such as text and images. One significant outcome of CLIP is its capability to allow users to search for images using text as a query, as well as vice versa. This is achieved via a joint embedding of images and text data that can, for instance, be used to search for similar items. Despite efficient query processing techniques such as approximate nearest neighbor search, the results may lack precision and completeness. We introduce CLIP-Branches, a novel text-image search engine built upon the CLIP architecture. Our approach enhances traditional text-image search engines by incorporating an interactive fine-tuning phase, which allows the user to further concretize the search query by iteratively defining positive and negative examples. Our framework involves training a classification model given the additional user feedback and essentially outputs all positively classified instances of the entire data catalog. By building upon recent techniques, this inference phase, however, is not implemented by scanning the entire data catalog, but by employing efficient index structures pre-built for the data. Our results show that the fine-tuned results can improve the initial search outputs in terms of relevance and accuracy while maintaining swift response times"
"CLIP-Branches: Interactive Fine-Tuning for Text-Image Retrieval.","2024","CoRR","Christian Lülf, Denis Mayr Lima Martins, Marcos Antonio Vaz Salles, Yongluan Zhou, Fabian Gieseke","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2406-13322",""
"Generating Realistic Arm Movements in Reinforcement Learning: A Quantitative Comparison of Reward Terms and Task Requirements.","2024","CoRR","Jhon Charaja, Isabell Wochner, Pierre Schumacher, Winfried Ilg, Martin A. Giese, Christophe Maufroy, Andreas Bulling, Syn Schmitt, Daniel F. B. Haeufle","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2402-13949","Mimicking of human-like arm movement characteristics involves considering three factors during control policy synthesis: (a) task requirements, (b) noise during movement execution, and (c) optimality principles. Previous studies showed that when these factors (a-c) are considered individually, it is possible to synthesize arm movements that either kinematically match experimental data or reproduce the stereotypical triphasic muscle activation pattern. However, no quantitative comparison has assessed the realism of arm movements generated by each factor, nor has it been determined whether combining these factors results in movements with human-like kinematic characteristics and the triphasic muscle pattern. To investigate this, we used reinforcement learning to learn a control policy for a musculoskeletal arm model, aiming to discern which combination of factors (a-c) results in realistic arm movements according to four frequently reported stereotypical characteristics. Our findings indicate that incorporating velocity and acceleration requirements into the reaching task, employing reward terms that minimize mechanical work, hand jerk, and control effort, along with the inclusion of noise during movement, leads to realistic human arm movements by reinforcement learning. We expect that the gained insights will help in the future to better predict desired arm movements and corrective forces in wearable assistive devices."
"GeoFault: A well-founded fault ontology for interoperability in geological modeling.","2024","Comput. Geosci.","Yuanwei Qu, Michel Perrin, Anita Torabi, Mara Abel, Martin Giese","Journal Articles","https://dblp.org/rec/journals/gandc/QuPTAG24",""
"Parallel Backpropagation for Shared-Feature Visualization.","2024","CoRR","Alexander Lappe, Anna Bognár, Ghazaleh Ghamkhari Nejad, Albert Mukovskiy, Lucas Martini, Martin A. Giese, Rufin Vogels","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2405-09827","High-level visual brain regions contain subareas in which neurons appear to respond more strongly to examples of a particular semantic category, like faces or bodies, rather than objects. However, recent work has shown that while this finding holds on average, some out-of-category stimuli also activate neurons in these regions. This may be due to visual features common among the preferred class also being present in other images. Here, we propose a deep-learning-based approach for visualizing these features. For each neuron, we identify relevant visual features driving its selectivity by modelling responses to images based on latent activations of a deep neural network. Given an out-of-category image which strongly activates the neuron, our method first identifies a reference image from the preferred category yielding a similar feature activation pattern. We then backpropagate latent activations of both images to the pixel level, while enhancing the identified shared dimensions and attenuating non-shared features. The procedure highlights image regions containing shared features driving responses of the model neuron. We apply the algorithm to novel recordings from body-selective regions in macaque IT cortex in order to understand why some images of objects excite these neurons. Visualizations reveal object parts which resemble parts of a macaque body, shedding light on neural preference of these objects."
"Towards Representing Processes and Reasoning with Process Descriptions on the Web.","2024","TGDK","Andreas Harth, Tobias Käfer, Anisa Rula, Jean-Paul Calbimonte, Eduard Kamburjan, Martin Giese","Journal Articles","https://dblp.org/rec/journals/tgdk/HarthKRCKG24","We work towards a vocabulary to represent processes and temporal logic specifications as graph-structured data. Different fields use incompatible terminologies for describing essentially the same process-related concepts. In addition, processes can be represented from different perspectives and levels of abstraction: both state-centric and event-centric perspectives offer distinct insights into the underlying processes. In this work, we strive to unify the representation of processes and related concepts by leveraging the power of knowledge graphs. We survey approaches to representing processes and reasoning with process descriptions from different fields and provide a selection of scenarios to help inform the scope of a unified representation of processes. We focus on processes that can be executed and observed via web interfaces. We propose to provide a representation designed to combine state-centric and event-centric perspectives while incorporating temporal querying and reasoning capabilities on temporal logic specifications. A standardised vocabulary and representation for processes and temporal specifications would contribute towards bridging the gap between the terminologies from different fields and fostering the broader application of methods involving temporal logics, such as formal verification and program synthesis."
"A Geological Case Study on Semantically Triggered Processes.","2023","ESWC","Yuanwei Qu, Eduard Kamburjan, Martin Giese","Conference and Workshop Papers","https://dblp.org/rec/conf/esws/QuKG23",""
"Fast Search-By-Classification for Large-Scale Databases Using Index-Aware Decision Trees and Random Forests.","2023","Proc. VLDB Endow.","Christian Lülf, Denis Mayr Lima Martins, Marcos Antonio Vaz Salles, Yongluan Zhou, Fabian Gieseke","Journal Articles","https://dblp.org/rec/journals/pvldb/LulfMSZG23","The vast amounts of data collected in various domains pose great challenges to modern data exploration and analysis. To find ""interesting"" objects in large databases, users typically define a query using positive and negative example objects and train a classification model to identify the objects of interest in the entire data catalog. However, this approach requires a scan of all the data to apply the classification model to each instance in the data catalog, making this method prohibitively expensive to be employed in large-scale databases serving many users and queries interactively. In this work, we propose a novel framework for such search-by-classification scenarios that allows users to interactively search for target objects by specifying queries through a small set of positive and negative examples. Unlike previous approaches, our framework can rapidly answer such queries at low cost without scanning the entire database. Our framework is based on an index-aware construction scheme for decision trees and random forests that transforms the inference phase of these classification models into a set of range queries, which in turn can be efficiently executed by leveraging multidimensional indexing structures. Our experiments show that queries over large data catalogs with hundreds of millions of objects can be processed in a few seconds using a single server, compared to hours needed by classical scanning-based approaches."
"Generating Sparse Counterfactual Explanations for Multivariate Time Series.","2023","ICANN","Jana Lang, Martin A. Giese, Winfried Ilg, Sebastian Otte","Conference and Workshop Papers","https://dblp.org/rec/conf/icann/LangGIO23","Since neural networks play an increasingly important role in critical sectors, explaining network predictions has become a key research topic. Counterfactual explanations can help to understand why classifier models decide for particular class assignments and, moreover, how the respective input samples would have to be modified such that the class prediction changes. Previous approaches mainly focus on image and tabular data. In this work we propose SPARCE, a generative adversarial network (GAN) architecture that generates SPARse Counterfactual Explanations for multivariate time series. Our approach provides a custom sparsity layer and regularizes the counterfactual loss function in terms of similarity, sparsity, and smoothness of trajectories. We evaluate our approach on real-world human motion datasets as well as a synthetic time series interpretability benchmark. Although we make significantly sparser modifications than other approaches, we achieve comparable or better performance on all metrics. Moreover, we demonstrate that our approach predominantly modifies salient time steps and features, leaving non-salient inputs untouched."
"GeoFault: A well-founded fault ontology for interoperability in geological modeling.","2023","CoRR","Yuanwei Qu, Michel Perrin, Anita Torabi, Mara Abel, Martin Giese","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2302-07059","Geological modeling currently uses various computer-based applications. Data harmonization at the semantic level by means of ontologies is essential for making these applications interoperable. Since geo-modeling is currently part of multidisciplinary projects, semantic harmonization is required to model not only geological knowledge but also to integrate other domain knowledge at a general level. For this reason, the domain ontologies used for describing geological knowledge must be based on a sound ontology background to ensure the described geological knowledge is integratable. This paper presents a domain ontology: GeoFault, resting on the Basic Formal Ontology BFO (Arp et al., 2015) and the GeoCore ontology (Garcia et al., 2020). It models the knowledge related to geological faults. Faults are essential to various industries but are complex to model. They can be described as thin deformed rock volumes or as spatial arrangements resulting from the different displacements of geological blocks. At a broader scale, faults are currently described as mere surfaces, which are the components of complex fault arrays. The reference to the BFO and GeoCore package allows assigning these various fault elements to define ontology classes and their logical linkage within a consistent ontology framework. The GeoFault ontology covers the core knowledge of faults 'strico sensu,' excluding ductile shear deformations. This considered vocabulary is essentially descriptive and related to regional to outcrop scales, excluding microscopic, orogenic, and tectonic plate structures. The ontology is molded in OWL 2, validated by competency questions with two use cases, and tested using an in-house ontology-driven data entry application. The work of GeoFault provides a solid framework for disambiguating fault knowledge and a foundation of fault data integration for the applications and the users."
"Multi-Domain Norm-referenced Encoding Enables Data Efficient Transfer Learning of Facial Expression Recognition.","2023","CoRR","Michael Stettler, Alexander Lappe, Nick Taubert, Martin A. Giese","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2304-02309","People can innately recognize human facial expressions in unnatural forms, such as when depicted on the unusual faces drawn in cartoons or when applied to an animal's features. However, current machine learning algorithms struggle with out-of-domain transfer in facial expression recognition (FER). We propose a biologically-inspired mechanism for such transfer learning, which is based on norm-referenced encoding, where patterns are encoded in terms of difference vectors relative to a domain-specific reference vector. By incorporating domain-specific reference frames, we demonstrate high data efficiency in transfer learning across multiple domains. Our proposed architecture provides an explanation for how the human brain might innately recognize facial expressions on varying head shapes (humans, monkeys, and cartoon avatars) without extensive training. Norm-referenced encoding also allows the intensity of the expression to be read out directly from neural unit activity, similar to face-selective neurons in the brain. Our model achieves a classification accuracy of 92.15\% on the FERG dataset with extreme data efficiency. We train our proposed mechanism with only 12 images, including a single image of each class (facial expression) and one image per domain (avatar). In comparison, the authors of the FERG dataset achieved a classification accuracy of 89.02\% with their FaceExpr model, which was trained on 43,000 images."
"Neurodynamical Model of the Visual Recognition of Dynamic Bodily Actions from Silhouettes.","2023","ICANN","Prerana Kumar, Nick Taubert, Rajani Raman, Anna Bognár, Ghazaleh Ghamkhari Nejad, Rufin Vogels, Martin A. Giese","Conference and Workshop Papers","https://dblp.org/rec/conf/icann/KumarTRBNVG23",""
"One Hip Wonder: 1D-CNNs Reduce Sensor Requirements for Everyday Gait Analysis.","2023","ICANN","Jens Seemann, Tim Loris, Lukas Weber, Matthis Synofzik, Martin A. Giese, Winfried Ilg","Conference and Workshop Papers","https://dblp.org/rec/conf/icann/SeemannLWSGI23",""
"RapidEarth: A Search-by-Classification Engine for Large-Scale Geospatial Imagery.","2023","SIGSPATIAL/GIS","Christian Lülf, Denis Mayr Lima Martins, Marcos Antonio Vaz Salles, Yongluan Zhou, Fabian Gieseke","Conference and Workshop Papers","https://dblp.org/rec/conf/gis/LulfMSZG23","Data exploration and analysis in various domains often necessitate the search for specific objects in massive databases. A common search strategy, often known as search-by-classification, resorts to training machine learning models on small sets of positive and negative samples and to performing inference on the entire database to discover additional objects of interest. While such an approach often yields very good results in terms of classification performance, the entire database usually needs to be scanned, a process that can easily take several hours even for medium-sized data catalogs. In this work, we present RapidEarth, a geospatial search-by-classification engine that allows analysts to rapidly search for interesting objects in very large data collections of satellite imagery in a matter of seconds, without the need to scan the entire data catalog. RapidEarth embodies a co-design of multidimensional indexing structures and decision branches, a recently proposed variant of classical decision trees. These decision branches allow RapidEarth to transform the inference phase into a set of range queries, which can be efficiently processed by leveraging the aforementioned multidimensional indexing structures. The main contribution of this work is a geospatial search engine that implements these technical findings."
"The contribution of dynamics to macaque body and face patch responses.","2023","NeuroImage","Anna Bognár, Rajani Raman, Nick Taubert, Yordanka Zafirova, Baichen Li, Martin A. Giese, Béatrice de Gelder, Rufin Vogels","Journal Articles","https://dblp.org/rec/journals/neuroimage/BognarRTZLGGV23",""
