"title","year","venue","authors","type","url","abstract"
"How Aligned are Different Alignment Metrics?","2024","CoRR","Jannis Ahlert, Thomas Klein, Felix A. Wichmann, Robert Geirhos","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2407-07530",""
"Immediate generalisation in humans but a generalisation lag in deep neural networks - evidence for representational divergence?","2024","CoRR","Lukas S. Huber, Fred W. Mast, Felix A. Wichmann","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2402-09303",""
"Are Deep Neural Networks Adequate Behavioural Models of Human Visual Perception?","2023","CoRR","Felix A. Wichmann, Robert Geirhos","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2305-17023","Deep neural networks (DNNs) are machine learning algorithms that have revolutionized computer vision due to their remarkable successes in tasks like object classification and segmentation. The success of DNNs as computer vision algorithms has led to the suggestion that DNNs may also be good models of human visual perception. In this article, we review evidence regarding current DNNs as adequate behavioral models of human core object recognition. To this end, we argue that it is important to distinguish between statistical tools and computational models and to understand model quality as a multidimensional concept in which clarity about modeling goals is key. Reviewing a large number of psychophysical and computational explorations of core object recognition performance in humans and DNNs, we argue that DNNs are highly valuable scientific tools but that, as of today, DNNs should only be regarded as promising-but not yet adequate-computational models of human core object recognition behavior. On the way, we dispel several myths surrounding DNNs in vision science. Expected final online publication date for the Annual Review of Vision Science, Volume 9 is September 2023. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates."
"Neither hype nor gloom do DNNs justice.","2023","CoRR","Felix A. Wichmann, Simon Kornblith, Robert Geirhos","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2312-05355","Abstract
	  Neither the hype exemplified in some exaggerated claims about deep neural networks (DNNs), nor the gloom expressed by Bowers et al. do DNNs as models in vision science justice: DNNs rapidly evolve, and today's limitations are often tomorrow's successes. In addition, providing explanations as well as prediction and image-computability are model desiderata; one should not be favoured at the expense of the other."
