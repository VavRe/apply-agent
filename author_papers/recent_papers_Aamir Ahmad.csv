"title","year","venue","authors","type","url","abstract"
"A Hybrid Mutual Authentication Approach for Artificial Intelligence of Medical Things.","2024","IEEE Internet Things J.","Mian Ahmad Jan, Wenjing Zhang, Aamir Akbar, Houbing Song, Rahim Khan, Samia Allaoua Chelloug","Journal Articles","https://dblp.org/rec/journals/iotj/JanZASKC24","Artificial Intelligence of Medical Things (AIoMT) is a hybrid of the Internet of Medical Things (IoMT) and artificial intelligence to materialize the acquisition of real-time data via the smart wearable devices. Due to a diverse geographical environment of IoMT, secure, and reliable communication among these devices is a challenging task that needs to be resolved on priority basis. For this purpose, numerous device-focused authentication approaches have been proposed in the literature, however, the problem still persists. This article introduces an advanced, secured, and efficient solution for the IoMT by leveraging a lightweight mutual authentication scheme as well as facilitating AI-enabled Big Data analytics and predictive modeling. The proposed approach is specifically designed to establish secured communication between wearable sensing devices and servers within IoMT by exploiting the desirable features of cloud–edge paradigm. In this approach, every device needs to verify whether the requesting wearable device is legitimate or not and this process needs to be carried out prior to the actual communication. Our proposed approach employs a hybrid of Advanced Encryption Standard, i.e., AES-128 bit and medium access control (MAC) for the establishment of secured communication sessions. In addition, the proposed approach utilizes real-time data collection from wearable devices, enabling predictive modeling for the early detection of health anomalies, thereby, enhancing the patient outcomes of a specific disease. This continuously adaptive approach excels in real-time decision making, promptly alerting healthcare professionals of potential risks. Simulation results have verified that the proposed approach serves an ideal solution for the resource-constrained devices by achieving the expected level of authenticity through minimum possible communication and processing overhead. Additionally, this scheme is prune against well-known security attacks in the AIoMT infrastructures."
"Adaptive Reinforcement Learning for Robot Control.","2024","CoRR","Yu Tang Liu, Nilaksh Singh, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2404-18713","In this paper, a stable reinforcement learning control approach using neural networks (NNs) is developed for the trajectory tracking of an n-link rigid robot manipulator. The considered systems are in discrete time form. The proposed controller design consists of two NNs. One is the critic network that is used to approximate the long-term cost function, whereas other is that the action NN is employed to generate the system input. Then, an optimal control input can be obtained compared with other robot manipulator systems. Using the Lyapunov approach, the tracking error and weight estimates are proven to be semi-global uniformly ultimately bounded. A simulation example is employed to illustrate the effectiveness of the proposed controller."
"Airship Formations for Animal Motion Capture and Behavior Analysis.","2024","CoRR","Eric Price 0002, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2404-08986","AbstractAn automatic, quick, accurate, and scalable method for animal behavior inference using only videos of animals offers unprecedented opportunities to understand complex biological phenomena and answer challenging ecological questions. The advent of sophisticated machine learning techniques now allows the development and implementation of such a method. However, apart from developing a network model that infers animal behavior from video inputs, the key challenge is to obtain sufficient labeled (annotated) data to successfully train that network - a laborious task that needs to be repeated for every species and/or animal system. Here, we propose solutions for both problems, i) a novel methodology for rapidly generating large amounts of annotated data of animals from videos and ii) using it to reliably train deep neural network models to infer the different behavioral states of every animal in each frame of the video. Our method’s workflow is bootstrapped with a relatively small amount of manually-labeled video frames. We develop and implement this novel method by building upon the open-source tool Smarter-LabelMe, leveraging deep convolutional visual detection and tracking in combination with our behavior inference model to quickly produce large amounts of reliable training data. We demonstrate the effectiveness of our method on aerial videos of plains and Grévy’s Zebras (Equus quaggaandEquus grevyi). We fully open-source the code1of our method as well as provide large amounts of accurately-annotated video datasets2of zebra behavior using our method. A video abstract of this paper is available here3."
"An Optimized Harris Hawks Algorithm for Enhancing ANN Performance in Prediction Tasks Applied in Sales Domain.","2024","ICCSCE","Bibi Aamirah Shafaa Emambocus, Muhammed Basheer Jasser, Shou Heng Tan, Samuel Mofoluwa Ajibade, Hui Na Chua, Richard T. K. Wong, Ahmad Sahban Rafsanjani","Conference and Workshop Papers","https://dblp.org/rec/conf/iccsce/EmambocusJTACWR24","Sales prediction, the process of predicting future sales performance based on past information, offers valuable information to businesses, allowing them to make informed and profitable decisions. This can be done using machine learning, specifically Artificial Neural Networks (ANNs) which have proven to be effective for prediction tasks. A requisite process before using ANNs as prediction models is its training which is commonly done using back-propagation algorithms. Recently, it has been noticed that swarm intelligence algorithms are better training algorithms for ANNs than backpropagation. In this paper, we propose to employ a high-performing swarm intelligence algorithm, Harris Hawks Optimization (HHO) for the training of ANNs applied to the prediction of iPhone sales in Malaysia. Moreover, we propose an optimized Harris Hawks algorithm and apply it for training the same prediction models. Both the original and optimized HHO algorithms are found to be able to better train the prediction models compared to the usual backpropagation algorithm. Furthermore, the proposed optimized HHO algorithm is found to have higher effectiveness than the original HHO as the ANNs trained by the optimized HHO can achieve a root mean square error of 89.6789 during the training as compared to 112.2448 by those trained using the original HHO."
"Behavior and Characteristics of Ransomware - A Survey.","2024","ICCR","Naeem Akhtar Malik, Amir Mohammad Delshadi, Muhammad Ibrar, Khalid Hamid, Muhammad Aamir 0007, Fahad Ahmed, Gulzar Ahmad","Conference and Workshop Papers","https://dblp.org/rec/conf/iccr/MalikDIHAAA24",""
"Blockchain-Based Logging to Defeat Malicious Insiders: The Case of Remote Health Monitoring Systems.","2024","IEEE Access","Hamza Javed, Zainab Abaid, Shahid Akbar, Kifayat Ullah 0004, Ashfaq Ahmad, Aamir Saeed, Hashim Ali, Yazeed Yasin Ghadi, Tahani Jaser Alahmadi, Hend Khalid Alkahtani, Ali Raza","Journal Articles","https://dblp.org/rec/journals/access/JavedAAUASAGAAR24","IoT-based remote health monitoring is a promising technology to support patients who are unable to travel to medical facilities. Due to the sensitivity of health data, it is important to secure it against all possible threats. While a great deal of work has been done to secure IoT device-cloud communication and health records on the cloud, insider attacks remain a significant challenge. Malicious insiders may tamper, steal or change patients’ health data, which results in a loss of patient trust in these systems. Audit logs in the cloud, which may point to illegal data access, may also be erased or forged by malicious insiders as they tend to have technical knowledge and privileged access to the system. Thus, in this work, we propose a Cloud Access Security Broker (CASB) model that (a) logs every action performed on user data and (b) secures those logs by placing them in a private blockchain that is viewable by the data owners (i.e., patients). Patients can query the blockchain, track their data’s movement, and be alerted if their data has been accessed by an administrator or moved outside the cloud storage. In this work, we practically implement a web application that receives health data from patients, a CASB that securely stores the records in the cloud, and integrate a private blockchain that immediately logs all actions happening in the backend of the web application and CASB. We evaluate the system’s security and performance under varying numbers of patients and actions."
"End-to-End Thermal Updraft Detection and Estimation for Autonomous Soaring Using Temporal Convolutional Networks.","2024","ICRA","Christian Gall, Walter Fichter, Aamir Ahmad","Conference and Workshop Papers","https://dblp.org/rec/conf/icra/GallFA24","Exploiting thermal updrafts to gain altitude can significantly extend the endurance of fixed-wing aircraft, as has been demonstrated by human glider pilots for decades. In this work, we present a novel end-to-end deep learning approach for the simultaneous detection of multiple thermal updrafts and the estimation of their properties — a key capability to let autonomous unmanned aerial vehicles soar as well. In contrast to previous works, our approach does not require separate algorithms for the detection of individual updrafts. Instead, a sequence of sensor measurements from a time window of interest can be directly fed into our temporal convolutional network, which estimates the position, strength, and spread of the encountered updrafts. We demonstrated in simulations that our approach can reliably detect updrafts solely based on measurements of the aircraft’s position and the local vertical wind velocity. Nevertheless, our method can additionally make use of measurements of the roll moment induced by updrafts, which improves the precision further. Compared with a particle-filter-based method, we can determine the correct number of encountered updrafts with an accuracy of 99.99% instead of 79.50%, significantly improve the precision of strength as well as spread estimates, and reduce the computational demand."
"Enhancing brain tumor diagnosis: an optimized CNN hyperparameter model for improved accuracy and reliability.","2024","PeerJ Comput. Sci.","Abdullah A. Asiri, Ahmad Shaf, Tariq Ali, Muhammad Aamir 0007, Muhammad Irfan 0008, Saeed Alqahtani","Journal Articles","https://dblp.org/rec/journals/peerj-cs/AsiriSAAIA24","Hyperparameter tuning plays a pivotal role in the accuracy and reliability of convolutional neural network (CNN) models used in brain tumor diagnosis. These hyperparameters exert control over various aspects of the neural network, encompassing feature extraction, spatial resolution, non-linear mapping, convergence speed, and model complexity. We propose a meticulously refined CNN hyperparameter model designed to optimize critical parameters, including filter number and size, stride padding, pooling techniques, activation functions, learning rate, batch size, and the number of layers. Our approach leverages two publicly available brain tumor MRI datasets for research purposes. The first dataset comprises a total of 7,023 human brain images, categorized into four classes: glioma, meningioma, no tumor, and pituitary. The second dataset contains 253 images classified as “yes” and “no.” Our approach delivers exceptional results, demonstrating an average 94.25% precision, recall, and F1-score with 96% accuracy for dataset 1, while an average 87.5% precision, recall, and F1-score, with accuracy of 88% for dataset 2. To affirm the robustness of our findings, we perform a comprehensive comparison with existing techniques, revealing that our method consistently outperforms these approaches. By systematically fine-tuning these critical hyperparameters, our model not only enhances its performance but also bolsters its generalization capabilities. This optimized CNN model provides medical experts with a more precise and efficient tool for supporting their decision-making processes in brain tumor diagnosis."
"Multi-Task Reinforcement Learning in Continuous Control with Successor Feature-Based Concurrent Composition.","2024","ECC","Yu Tang Liu, Aamir Ahmad","Conference and Workshop Papers","https://dblp.org/rec/conf/eucc/LiuA24","Deep reinforcement learning (DRL) frameworks are increasingly used to solve high-dimensional continuouscontrol tasks in robotics. However, due to the lack of sample efficiency, applying DRL for online learning is still practically infeasible in the robotics domain. One reason is that DRL agents do not leverage the solution of previous tasks for new tasks. Recent work on multi-task DRL agents based on successor features (SFs) has proven to be quite promising in increasing sample efficiency. In this work, we present a new approach that unifies two prior multi-task RL frameworks, SF-GPI and value composition, and adapts them to the continuous control domain. We exploit compositional properties of successor features to compose a policy distribution from a set of primitives without training any new policy. Lastly, to demonstrate the multi-tasking mechanism, we present our proof-of-concept benchmark environments, Pointmass and Pointer, based on IsaacGym, which facilitates large-scale parallelization to accelerate the experiments. Our experimental results show that our multi-task agent has single-task performance on par with soft actor-critic (SAC), and the agent can successfully transfer to new unseen tasks. We provide our code as open-source at https://github.com/robot-perception-group/concurrent_composition for the benefit of the community."
"Non-orthogonal multiple access-based MEC for energy-efficient task offloading in e-commerce systems.","2024","J. Cloud Comput.","Xiao Zheng, Muhammad Tahir, Khursheed Aurangzeb, Muhammad Shahid Anwar, Muhammad Aamir 0002, Ahmad Farzan, Rizwan Ullah","Journal Articles","https://dblp.org/rec/journals/jcloudc/ZhengTAAAFU24","AbstractMobile edge computing (MEC) reduces the latency for end users to access applications deployed at the edge by offloading tasks to the edge. With the popularity of e-commerce and the expansion of business scale, server load continues to increase, and energy efficiency issues gradually become more prominent. Computation offloading has received widespread attention as a technology that effectively reduces server load. However, how to improve energy efficiency while ensuring computing requirements is an important challenge facing computation offloading. To solve this problem, using non-orthogonal multiple access (NOMA) to increase the efficiency of multi-access wireless transmission, MEC supporting NOMA is investigated in the research. Computing resources will be divided into separate sub-computing that will be handled via e-commerce terminals or transferred to edge sides by reutilizing radio resources, we put forward a Group Switching Matching Algorithm Based on Resource Unit Allocation (GSM-RUA) algorithm that is multi-dimensional. To this end, we first formulate this task allocation problem as a long-term stochastic optimization problem, which we then convert to three short-term deterministic sub-programming problems using Lyapunov optimization, namely, radio resource allocation in a large timescale, computation resource allocating and splitting in a small-time frame. Of the 3 short-term deterministic sub-programming problems, the first sub-programming problem can be remodeled into a 1 to n matching problem, which can be solved using the block-shift-matching-based radio resource allocation method. The latter two sub-programming problems are then transformed into two continuous convex problems by relaxation and then solved easily. We then use simulations to prove that our GSM-RUA algorithm is superior to the state-of-the-art resource management algorithms in terms of energy consumption, efficiency and complexity for e-commerce scenarios."
"Optimizing Transdermal Insulin Delivery: A Simulation Study on the Efficacy of Sonophoretic Transducer Arrays at Low Voltages.","2024","IEEE Access","Sehreen Moorat, Ahsan Ahmad Ursani, Aftab Ahmed Memon, Muhammad Aamir Panhwar","Journal Articles","https://dblp.org/rec/journals/access/MooratUMP24","Insulin therapy is integral to the treatment of diabetes mellitus. Epidemiologic studies have shown its benefits both in terms of improving glycemic control and reducing the risk for long-term diabetic complications for both type 1 and type 2 diabetes. Despite these benefits, barriers to insulin therapy are well documented and include perceived inconvenience, needle anxiety, and portability of device in case of insulin pumps. Therefore, this study aims to design and simulate a low frequency sonophoretic array for transdermal insulin delivery. This study utilizes COMSOL Multiphysics software to simulate the transducer used to increase the skin permeability for delivering drugs. It consists of $8\times 5$ array of a piezoelectric elements operated at 100 kHz and 1 volt. To evaluate the effectiveness of the transducer, an intricate skin model has been developed that includes all anatomical layers extending to the bone. The skin layers, particularly muscle and bone, exhibit reflective properties, leading to the formation of a standing wave. This phenomenon arises from the impedance mismatch between muscle and bone. Standing wave served to promote the transportation of the drug into the dermal layer, rich with capillary networks. We found that applying standing wave with 100 kHz the achieved pressure of 0.3 MPa induced acoustic streaming for the drug flow of $1605~\frac {\mathrm {\mu g}}{{\mathrm {cm}}^{2}}$ per 24 hours. Also, the precise modulation of ultrasound frequency and voltage is key to controlling peak acoustic pressure, thereby regulating the rate of insulin delivery through the skin."
"Reinforcement learning based autonomous multi-rotor landing on moving platforms.","2024","Auton. Robots","Pascal Goldschmid, Aamir Ahmad","Journal Articles","https://dblp.org/rec/journals/arobots/GoldschmidA24","Multi-rotor UAVs suffer from a restricted range and flight duration due to limited battery capacity. Autonomous landing on a 2D moving platform offers the possibility to replenish batteries and offload data, thus increasing the utility of the vehicle. Classical approaches rely on accurate, complex and difficult-to-derive models of the vehicle and the environment. Reinforcement learning (RL) provides an attractive alternative due to its ability to learn a suitable control policy exclusively from data during a training procedure. However, current methods require several hours to train, have limited success rates and depend on hyperparameters that need to be tuned by trial-and-error. We address all these issues in this work. First, we decompose the landing procedure into a sequence of simpler, but similar learning tasks. This is enabled by applying two instances of the same RL based controller trained for 1D motion for controlling the multi-rotor’s movement in both the longitudinal and the lateral directions. Second, we introduce a powerful state space discretization technique that is based on i) kinematic modeling of the moving platform to derive information about the state space topology and ii) structuring the training as a sequential curriculum using transfer learning. Third, we leverage the kinematics model of the moving platform to also derive interpretable hyperparameters for the training process that ensure sufficient maneuverability of the multi-rotor vehicle. The training is performed using the tabular RL method Double Q-Learning. Through extensive simulations we show that the presented method significantly increases the rate of successful landings, while requiring less training time compared to other deep RL approaches. Furthermore, for two comparison scenarios it achieves comparable performance than a cascaded PI controller. Finally, we deploy and demonstrate our algorithm on real hardware. For all evaluation scenarios we provide statistics on the agent’s performance. Source code is openly available at https://github.com/robot-perception-group/rl_multi_rotor_landing."
"Resource-Optimized Vehicular Edge Networks With Fairness Constraints.","2024","IEEE Access","Aamir Rashid, Latif U. Khan, Naeem Khan, Hong Min, Ayaz Ahmad, Shabir Ahmad","Journal Articles","https://dblp.org/rec/journals/access/RashidKKMAA24","Intelligent transportation systems (ITSs) have witnessed a rising interest from researchers because of their promising features. These features include lane change assistance, infotainment, and collision avoidance, among others. To effectively operate ITSs for these functions, there is a need for edge computing. One can install edge computing servers at the roadside units (RSUs). There must be seamless communication between the edge servers and the cars. Additionally, there will be some cars that experience higher delays and thus, are not preferable because they will highly degrade the performance. Therefore, in this work, we consider a vehicular network scenario and define a cost function that takes into account the latency that is determined by the car’s computing frequency, association, and resource allocation while considering fairness constraints. Our cost function is to minimize the total latency (i.e., both local computing latency and transmission latency). The cost of the optimization problem is minimized by optimizing the car’s local frequency allocation, resource allocation, and association. The problem is separable, therefore, we first compute the local frequencies of the cars using a convex optimizer. Next, we split the core problem into two separate problems: (a) the distribution of resources and (b) association, because the last defined problem (joint association and resource allocation) is NP-hard. We then suggest an iterative solution. In the end, we offer numerical findings to support the suggested solution."
"RiceNet: A deep convolutional neural network approach for classification of rice varieties.","2024","Expert Syst. Appl.","Nusrat Mohi ud din, Assif Assad, Rayees Ahmad Dar, Muzafar Rasool, Saqib Ul Sabha, Tabasum Majeed, Zahir Ul Islam, Wahid Gulzar, Aamir Yaseen","Journal Articles","https://dblp.org/rec/journals/eswa/dinADRSMIGY24",""
"ZebraPose: Zebra Detection and Pose Estimation using only Synthetic Data.","2024","CoRR","Elia Bonetto, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2408-10831",""
"Advancing Brain Tumor Classification through Fine-Tuned Vision Transformers: A Comparative Study of Pre-Trained Models.","2023","Sensors","Abdullah A. Asiri, Ahmad Shaf, Tariq Ali, Muhammad Ahmad Pasha, Muhammad Aamir 0007, Muhammad Irfan 0008, Saeed Alqahtani, Ahmad Joman Alghamdi, Ali H. Alghamdi, Abdullah Fahad A. Alshamrani, Magbool Alelyani, Sultan Alamri","Journal Articles","https://dblp.org/rec/journals/sensors/AsiriSAPAIAAAAAA23","This paper presents a comprehensive study on the classification of brain tumor images using five pre-trained vision transformer (ViT) models, namely R50-ViT-l16, ViT-l16, ViT-l32, ViT-b16, and ViT-b32, employing a fine-tuning approach. The objective of this study is to advance the state-of-the-art in brain tumor classification by harnessing the power of these advanced models. The dataset utilized for experimentation consists of a total of 4855 images in the training set and 857 images in the testing set, encompassing four distinct tumor classes. The performance evaluation of each model is conducted through an extensive analysis encompassing precision, recall, F1-score, accuracy, and confusion matrix metrics. Among the models assessed, ViT-b32 demonstrates exceptional performance, achieving a high accuracy of 98.24% in accurately classifying brain tumor images. Notably, the obtained results outperform existing methodologies, showcasing the efficacy of the proposed approach. The contributions of this research extend beyond conventional methods, as it not only employs cutting-edge ViT models but also surpasses the performance of existing approaches for brain tumor image classification. This study not only demonstrates the potential of ViT models in medical image analysis but also provides a benchmark for future research in the field of brain tumor classification."
"Identifying Neuropeptides via Evolutionary and Sequential Based Multi-Perspective Descriptors by Incorporation With Ensemble Classification Strategy.","2023","IEEE Access","Shahid Akbar, Heba G. Mohamed, Hashim Ali, Aamir Saeed, Aftab Ahmed Khan, Sarah Gul, Ashfaq Ahmad, Farman Ali 0002, Yazeed Yasin Ghadi, Muhammad Assam","Journal Articles","https://dblp.org/rec/journals/access/AkbarMASKGAAGA23",""
"Prediction of Amyloid Proteins Using Embedded Evolutionary & Ensemble Feature Selection Based Descriptors With eXtreme Gradient Boosting Model.","2023","IEEE Access","Shahid Akbar, Hashim Ali, Ashfaq Ahmad, Mahidur R. Sarker, Aamir Saeed, Ely Salwana 0001, Sarah Gul, Ahmad Khan, Farman Ali 0002","Journal Articles","https://dblp.org/rec/journals/access/AkbarAASSSGKA23","Amyloid proteins (AMYs) are usually an aggregate of insoluble fibrous that have major pathogenic effects on various tissues. However, its abnormal deposition may lead to several diseases i.e., Parkinson’s, Alzheimer’s, and type 2 diabetes. In addition, AMYs form amyloid aggregates when they are in a misfolded state. Therefore, it is crucial to accurately predict AMYs and their pathogenic characteristics. Various computational predictors have been presented for the accurate prediction of AMYs. Although, the effectiveness of these predictors is unsatisfactory due to their low generalization abilities and high training cost. In this attempt, we proposed an intelligent computational predictor for the accurate prediction of AMYs. The novel embedded evolutionary features are gathered using K-separated bigrams, and the Filter method into the evolutionary descriptors. Moreover, DDE-based enhanced frequency coupling information are gathered from the Amyloid sequences. Additionally, a multi-model vector is obtained by combining the features of the applied formulation techniques. To reduce the computational cost of the proposed model, the eXtreme Gradient Boosting-Recursive Feature Elimination (XGB-RFE) based high-ranked features are selected from the heterogeneous vector. In the next part, the optimal features are evaluated via several learners, i.e., XGBoost (XGB), Light Gradient Boosted Machine (LGBM), Support Vector Machine (SVM), Adaboost (ada), and Extra Trees classifier (ETC),. The proposed model reported an improved predictive prediction accuracy of 93.10% using training sequences and 89.67% using independent sequences, respectively. Which is $\sim 4$ % higher training accuracy than existing predictors. It is anticipated that our predictive approach will be useful for scientists and might play a key role in drug development and academic research."
"Hyperspectral Image Classification: Artifacts of Dimension Reduction on Hybrid CNN.","2021","CoRR","Muhammad Ahmad, Sidrah Shabbir, Rana Aamir Raza, Manuel Mazzara, Salvatore Distefano, Adil Mehmood Khan","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2101-10532","Convolutional Neural Networks (CNN) has been extensively studied for Hyperspectral Image Classification (HSIC) more specifically, 2D and 3D CNN models have proved highly efficient in exploiting the spatial and spectral information of Hyperspectral Images. However, 2D CNN only considers the spatial information and ignores the spectral information whereas 3D CNN jointly exploits spatial-spectral information at a high computational cost. Therefore, this work proposed a lightweight CNN (3D followed by 2D-CNN) model which significantly reduces the computational cost by distributing spatial-spectral feature extraction across a lighter model alongside a preprocessing that has been carried out to improve the classification results. Five benchmark Hyperspectral datasets (i.e., SalinasA, Salinas, Indian Pines, Pavia University, Pavia Center, and Botswana) are used for experimental evaluation. The experimental results show that the proposed pipeline outperformed in terms of generalization performance, statistical significance, and computational complexity, as compared to the state-of-the-art 2D/3D CNN models except commonly used computationally expensive design choices."
"Hyperspectral imaging-based unsupervised adulterated red chili content transformation for classification: Identification of red chili adulterants.","2021","Neural Comput. Appl.","Muhammad Hussain Khan, Zainab Saleem, Muhammad Ahmad, Sohaib Ahmed, Hamail Ayaz, Manuel Mazzara, Rana Aamir Raza","Journal Articles","https://dblp.org/rec/journals/nca/KhanSASAMR21",""
"Accelerated Video Annotation driven by Deep Detector and Tracker.","2023","CoRR","Eric Price 0002, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2302-09590",""
"Adaptive Capacity Task Offloading in Multi-Hop D2D-Based Social Industrial IoT.","2023","IEEE Trans. Netw. Sci. Eng.","Muhammad Ibrar, Lei Wang 0005, Aamir Akbar, Mian Ahmad Jan, Venki Balasubramanian, Gabriel-Miro Muntean, Nadir Shah","Journal Articles","https://dblp.org/rec/journals/tnse/IbrarWAJBMS23",""
"An Optimized Hybrid Dragonfly Algorithm Applied for Solving the Optimal Reactive Power Dispatch Problem in Smart Grids.","2023","ICCSCE","Bibi Aamirah Shafaa Emambocus, Muhammed Basheer Jasser, Shamuhammet Rejepov, Hui Na Chua, Ahmad Sahban Rafsanjani, Ismail Ahmed Al-Qasem Al-Hadi","Conference and Workshop Papers","https://dblp.org/rec/conf/iccsce/EmambocusJRCRA23",""
"Autonomous Blimp Control via $H_{\infty}$ Robust Deep Residual Reinforcement Learning.","2023","CASE","Yang Zuo, Yu Tang Liu, Aamir Ahmad","Conference and Workshop Papers","https://dblp.org/rec/conf/case/ZuoLA23",""
"Autonomous Blimp Control via H-infinity Robust Deep Residual Reinforcement Learning.","2023","CoRR","Yang Zuo, Yu Tang Liu, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2303-13929",""
"BERTDom: Protein Domain Boundary Prediction Using BERT.","2023","Comput. Informatics","Ahmad Haseeb, Maryam Bashir, Aamir Wali","Journal Articles","https://dblp.org/rec/journals/cai/HaseebBW23",""
"Enhanced Adaptive Brain-Computer Interface Approach for Intelligent Assistance to Disabled Peoples.","2023","Comput. Syst. Sci. Eng.","Ali Usman Gondal, Javed Ferzund, Ahmad Shaf, Muhammad Aamir 0007, Samar M. Alqhtani, Khlood M. Mehdar, Hanan Talal Halawani, Hassan A Alshamrani, Abdullah A. Asiri, Muhammad Irfan 0008","Journal Articles","https://dblp.org/rec/journals/csse/GondalFSAAMHAAI23",""
"GRADE: Generating Realistic Animated Dynamic Environments for Robotics Research.","2023","CoRR","Elia Bonetto, Chenghao Xu, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2303-04466",""
"Isolation of multiple electrocardiogram artifacts using independent vector analysis.","2023","PeerJ Comput. Sci.","Zahoor Uddin, Muhammad Altaf, Ayaz Ahmad, Aamir Qamar, Farooq Alam Orakzai","Journal Articles","https://dblp.org/rec/journals/peerj-cs/UddinAAQO23","Electrocardiogram (ECG) signals are normally contaminated by various physiological and nonphysiological artifacts. Among these artifacts baseline wandering, electrode movement and muscle artifacts are particularly difficult to remove. Independent component analysis (ICA) is a well-known technique of blind source separation (BSS) and is extensively used in literature for ECG artifact elimination. In this article, the independent vector analysis (IVA) is used for artifact removal in the ECG data. This technique takes advantage of both the canonical correlation analysis (CCA) and the ICA due to the utilization of second-order and high order statistics for un-mixing of the recorded mixed data. The utilization of recorded signals along with their delayed versions makes the IVA-based technique more practical. The proposed technique is evaluated on real and simulated ECG signals and it shows that the proposed technique outperforms the CCA and ICA because it removes the artifacts while altering the ECG signals minimally."
"MCR-DL: Mix-and-Match Communication Runtime for Deep Learning.","2023","IPDPS","Quentin Anthony, Ammar Ahmad Awan, Jeff Rasley, Yuxiong He, Aamir Shafi, Mustafa Abduljabbar, Hari Subramoni, Dhabaleswar K. Panda 0001","Conference and Workshop Papers","https://dblp.org/rec/conf/ipps/AnthonyARHSASP23",""
"Next-Gen brain tumor classification: pioneering with deep learning and fine-tuned conditional generative adversarial networks.","2023","PeerJ Comput. Sci.","Abdullah A. Asiri, Muhammad Aamir 0007, Tariq Ali, Ahmad Shaf, Muhammad Irfan 0008, Khlood M. Mehdar, Samar M. Alqhtani, Ali H. Alghamdi, Abdullah Fahad A. Alshamrani, Osama Mohammed Alshehri","Journal Articles","https://dblp.org/rec/journals/peerj-cs/AsiriAASIMAAAA23","Brain tumor has become one of the fatal causes of death worldwide in recent years, affecting many individuals annually and resulting in loss of lives. Brain tumors are characterized by the abnormal or irregular growth of brain tissues that can spread to nearby tissues and eventually throughout the brain. Although several traditional machine learning and deep learning techniques have been developed for detecting and classifying brain tumors, they do not always provide an accurate and timely diagnosis. This study proposes a conditional generative adversarial network (CGAN) that leverages the fine-tuning of a convolutional neural network (CNN) to achieve more precise detection of brain tumors. The CGAN comprises two parts, a generator and a discriminator, whose outputs are used as inputs for fine-tuning the CNN model. The publicly available dataset of brain tumor MRI images on Kaggle was used to conduct experiments for Datasets 1 and 2. Statistical values such as precision, specificity, sensitivity, F1-score, and accuracy were used to evaluate the results. Compared to existing techniques, our proposed CGAN model achieved an accuracy value of 0.93 for Dataset 1 and 0.97 for Dataset 2."
"Recent progress in sign language recognition: a review.","2023","Mach. Vis. Appl.","Aamir Wali, Roha Shariq, Sajdah Shoaib, Sukhan Amir, Asma Ahmad Farhan","Journal Articles","https://dblp.org/rec/journals/mva/WaliSSAF23",""
"Reinforcement Learning based Autonomous Multi-Rotor Landing on Moving Platforms.","2023","CoRR","Pascal Goldschmid, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2302-13192","Multi-rotor UAVs suffer from a restricted range and flight duration due to limited battery capacity. Autonomous landing on a 2D moving platform offers the possibility to replenish batteries and offload data, thus increasing the utility of the vehicle. Classical approaches rely on accurate, complex and difficult-to-derive models of the vehicle and the environment. Reinforcement learning (RL) provides an attractive alternative due to its ability to learn a suitable control policy exclusively from data during a training procedure. However, current methods require several hours to train, have limited success rates and depend on hyperparameters that need to be tuned by trial-and-error. We address all these issues in this work. First, we decompose the landing procedure into a sequence of simpler, but similar learning tasks. This is enabled by applying two instances of the same RL based controller trained for 1D motion for controlling the multi-rotor’s movement in both the longitudinal and the lateral directions. Second, we introduce a powerful state space discretization technique that is based on i) kinematic modeling of the moving platform to derive information about the state space topology and ii) structuring the training as a sequential curriculum using transfer learning. Third, we leverage the kinematics model of the moving platform to also derive interpretable hyperparameters for the training process that ensure sufficient maneuverability of the multi-rotor vehicle. The training is performed using the tabular RL method Double Q-Learning. Through extensive simulations we show that the presented method significantly increases the rate of successful landings, while requiring less training time compared to other deep RL approaches. Furthermore, for two comparison scenarios it achieves comparable performance than a cascaded PI controller. Finally, we deploy and demonstrate our algorithm on real hardware. For all evaluation scenarios we provide statistics on the agent’s performance. Source code is openly available at https://github.com/robot-perception-group/rl_multi_rotor_landing."
"SeAC: SDN-Enabled Adaptive Clustering Technique for Social-Aware Internet of Vehicles.","2023","IEEE Trans. Intell. Transp. Syst.","Aamir Akbar, Muhammad Ibrar, Mian Ahmad Jan, Lei Wang 0005, Nadir Shah, Houbing Herbert Song","Journal Articles","https://dblp.org/rec/journals/tits/AkbarIJWSS23",""
"SmartMocap: Joint Estimation of Human and Camera Motion Using Uncalibrated RGB Cameras.","2023","IEEE Robotics Autom. Lett.","Nitin Saini, Chun-Hao P. Huang, Michael J. Black, Aamir Ahmad","Journal Articles","https://dblp.org/rec/journals/ral/SainiHBA23",""
"StynMedGAN: Medical images augmentation using a new GAN model for improved diagnosis of diseases.","2023","J. Intell. Fuzzy Syst.","Aamir Wali, Muzammil Ahmad, Asma Naseer, Maria Tamoor, S. A. M. Gilani","Journal Articles","https://dblp.org/rec/journals/jifs/WaliANTG23","Deep networks require a considerable amount of training data otherwise these networks generalize poorly. Data Augmentation techniques help the network generalize better by providing more variety in the training data. Standard data augmentation techniques such as flipping, and scaling, produce new data that is a modified version of the original data. Generative Adversarial networks (GANs) have been designed to generate new data that can be exploited. In this paper, we propose a new GAN model, named StynMedGAN for synthetically generating medical images to improve the performance of classification models.  StynMedGAN builds upon the state-of-the-art styleGANv2 that has produced remarkable results generating all kinds of natural images. We introduce a regularization term that is a normalized loss factor in the existing discriminator loss of styleGANv2. It is used to force the generator to produce normalized images and penalize it if it fails. Medical imaging modalities, such as X-Rays, CT-Scans, and MRIs are different in nature, we show that the proposed GAN extends the capacity of styleGANv2 to handle medical images in a better way. This new GAN model (StynMedGAN) is applied to three types of medical imaging: X-Rays, CT scans, and MRI to produce more data for the classification tasks. To validate the effectiveness of the proposed model for the classification, 3 classifiers (CNN, DenseNet121, and VGG-16) are used. Results show that the classifiers trained with StynMedGAN-augmented data outperform other methods that only used the original data. The proposed model achieved 100%, 99.6%, and 100% for chest X-Ray, Chest CT-Scans, and Brain MRI respectively. The results are promising and favor a potentially important resource that can be used by practitioners and radiologists to diagnose different diseases."
"Supervised machine learning for jamming transition in traffic flow with fluctuations in acceleration and braking.","2023","Comput. Electr. Eng.","Naveed Ahmad Khan, Ghaylen Laouini, Fahad Sameer Alshammari, Majdi Khalid, Nudrat Aamir","Journal Articles","https://dblp.org/rec/journals/cee/KhanLAKA23",""
"Synthetic Data-Based Detection of Zebras in Drone Imagery.","2023","ECMR","Elia Bonetto, Aamir Ahmad","Conference and Workshop Papers","https://dblp.org/rec/conf/ecmr/BonettoA23","Nowadays, there is a wide availability of datasets that enable the training of common object detectors or human detectors. These come in the form of labelled real-world images and require either a significant amount of human effort, with a high probability of errors such as missing labels, or very constrained scenarios, e.g. VICON systems. On the other hand, uncommon scenarios, like aerial views, animals, like wild zebras, or difficult-to-obtain information, such as human shapes, are hardly available. To overcome this, synthetic data generation with realistic rendering technologies has recently gained traction and advanced research areas such as target tracking and human pose estimation. However, subjects such as wild animals are still usually not well represented in such datasets. In this work, we first show that a pre-trained YOLO detector can not identify zebras in real images recorded from aerial viewpoints. To solve this, we present an approach for training an animal detector using only synthetic data. We start by generating a novel synthetic zebra dataset using GRADE, a state-of-the-art framework for data generation. The dataset includes RGB, depth, skeletal joint locations, pose, shape and instance segmentations for each subject. We use this to train a YOLO detector from scratch. Through extensive evaluations of our model with real-world data from i) limited datasets available on the internet and ii) a new one collected and manually labelled by us, we show that we can detect zebras by using only synthetic data during training. The code, results, trained models, and both the generated and training data are provided as open-source at https://eliabntt.github.io/grade-rr."
"Viewpoint-Driven Formation Control of Airships for Cooperative Target Tracking.","2023","IEEE Robotics Autom. Lett.","Eric Price 0002, Michael J. Black, Aamir Ahmad","Journal Articles","https://dblp.org/rec/journals/ral/PriceBA23",""
"pAtbP-EnC: Identifying Anti-Tubercular Peptides Using Multi-Feature Representation and Genetic Algorithm-Based Deep Ensemble Model.","2023","IEEE Access","Shahid Akbar, Ali Raza, Tamara Al Shloul, Ashfaq Ahmad, Aamir Saeed, Yazeed Yasin Ghadi, Orken Mamyrbayev, Elsayed Tag-Eldin","Journal Articles","https://dblp.org/rec/journals/access/AkbarRSASGMT23","Mycobacterium tuberculosis, a highly perilous pathogen in humans, serves as the causative agent of tuberculosis (TB), affecting nearly 33% of the global population. With the increasing prevalence of multidrug-resistant TB, there is a need for novel and efficacious alternative therapies. Peptide therapies have emerged as a favorable alternative due to their remarkable specificity in targeting cells without affecting healthy cells. However, the experimental identification methods of anti-tubercular peptides (AtbPs) are labor-intensive and costly. Therefore, accurate prediction of AtbPs has become challenging due to the large number of peptide samples. In this paper, we propose an ensemble learning model to enhance the prediction outcomes by addressing the limitations of individual learning models. We formulate the training samples by utilizing four distinct representation methods: AAindex, Composition/Transition/Distribution, Dipeptide Deviation from Expected Mean, and Enhanced Grouped Amino Acid Composition to numerically encode peptide samples. The feature vectors extracted from these methods are fused to develop a compact vector. We evaluate the prediction rates using three different classification models, employing both individual and heterogeneous vectors. Furthermore, we enhance the prediction and training capabilities of the proposed model by using the predicted labels of the individual classifiers for implementing an ensemble deep model via a genetic algorithm. Through evaluation of both the training datasets and independent datasets, our proposed ensemble learner achieves impressive accuracies of 97.80%, 95.13%, 93.91%, and 94.17%, using RD training, MD training, RD independent, and MD independent datasets, respectively. Our findings demonstrate that the proposed pAtbP-EnC model outperforms existing predictors by reporting approximately 11% higher training accuracy. We conclude that the pAtbP-EnC predictor will be a considerable tool in the field of pharmaceutical design and research academia. The used datasets and the source code are publicly available at https://github.com/Intelligent-models/pAtbP-EnC2023."
"DynaPix SLAM: A Pixel-Based Dynamic SLAM Approach.","2023","CoRR","Chenghao Xu, Elia Bonetto, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2309-09879","In static environments, visual simultaneous localization and mapping (V-SLAM) methods achieve remarkable performance. However, moving objects severely affect core modules of such systems like state estimation and loop closure detection. To address this, dynamic SLAM approaches often use semantic information, geometric constraints, or optical flow to mask features associated with dynamic entities. These are limited by various factors such as a dependency on the quality of the underlying method, poor generalization to unknown or unexpected moving objects, and often produce noisy results, e.g. by masking static but movable objects or making use of predefined thresholds. In this paper, to address these trade-offs, we introduce a novel visual SLAM system, DynaPix, based on per-pixel motion probability values. Our approach consists of a new semantic-free probabilistic pixel-wise motion estimation module and an improved pose optimization process. Our per-pixel motion probability estimation combines a novel static background differencing method on both images and optical flows from splatted frames. DynaPix fully integrates those motion probabilities into both map point selection and weighted bundle adjustment within the tracking and optimization modules of ORB-SLAM2. We evaluate DynaPix against ORB-SLAM2 and DynaSLAM on both GRADE and TUM-RGBD datasets, obtaining lower errors and longer trajectory tracking times. We will release both source code and data upon acceptance of this work."
"Learning from synthetic data generated with GRADE.","2023","CoRR","Elia Bonetto, Chenghao Xu, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2305-04282","Recently, synthetic data generation and realistic rendering has advanced tasks like target tracking and human pose estimation. Simulations for most robotics applications are obtained in (semi)static environments, with specific sensors and low visual fidelity. To solve this, we present a fully customizable framework for generating realistic animated dynamic environments (GRADE) for robotics research, first introduced in [1]. GRADE supports full simulation control, ROS integration, realistic physics, while being in an engine that produces high visual fidelity images and ground truth data. We use GRADE to generate a dataset focused on indoor dynamic scenes with people and flying objects. Using this, we evaluate the performance of YOLO and Mask R-CNN on the tasks of segmenting and detecting people. Our results provide evidence that using data generated with GRADE can improve the model performance when used for a pre-training step. We also show that, even training using only synthetic data, can generalize well to real-world images in the same application domain such as the ones from the TUM-RGBD dataset. The code, results, trained models, and the generated data are provided as open-source at https://eliabntt.github.io/grade-rr."
"Multi-Task Reinforcement Learning in Continuous Control with Successor Feature-Based Concurrent Composition.","2023","CoRR","Yu Tang Liu, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2303-13935","Deep reinforcement learning (DRL) frameworks are increasingly used to solve high-dimensional continuouscontrol tasks in robotics. However, due to the lack of sample efficiency, applying DRL for online learning is still practically infeasible in the robotics domain. One reason is that DRL agents do not leverage the solution of previous tasks for new tasks. Recent work on multi-task DRL agents based on successor features (SFs) has proven to be quite promising in increasing sample efficiency. In this work, we present a new approach that unifies two prior multi-task RL frameworks, SF-GPI and value composition, and adapts them to the continuous control domain. We exploit compositional properties of successor features to compose a policy distribution from a set of primitives without training any new policy. Lastly, to demonstrate the multi-tasking mechanism, we present our proof-of-concept benchmark environments, Pointmass and Pointer, based on IsaacGym, which facilitates large-scale parallelization to accelerate the experiments. Our experimental results show that our multi-task agent has single-task performance on par with soft actor-critic (SAC), and the agent can successfully transfer to new unseen tasks. We provide our code as open-source at https://github.com/robot-perception-group/concurrent_composition for the benefit of the community."
"Simulation of Dynamic Environments for SLAM.","2023","CoRR","Elia Bonetto, Chenghao Xu, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2305-04286","Simulation engines are widely adopted in robotics. However, they lack either full simulation control, ROS integration, realistic physics, or photorealism. Recently, synthetic data generation and realistic rendering has advanced tasks like target tracking and human pose estimation. However, when focusing on vision applications, there is usually a lack of information like sensor measurements or time continuity. On the other hand, simulations for most robotics tasks are performed in (semi)static environments, with specific sensors and low visual fidelity. To solve this, we introduced in our previous work a fully customizable framework for generating realistic animated dynamic environments (GRADE) [1]. We use GRADE to generate an indoor dynamic environment dataset and then compare multiple SLAM algorithms on different sequences. By doing that, we show how current research over-relies on known benchmarks, failing to generalize. Our tests with refined YOLO and Mask R-CNN models provide further evidence that additional research in dynamic SLAM is necessary. The code, results, and generated data are provided as open-source at https://eliabntt.github.io/grade-rrSimulation of Dynamic Environments for SLAM"
"3-D-SIS: A 3-D-Social Identifier Structure for Collaborative Edge Computing Based Social IoT.","2022","IEEE Trans. Comput. Soc. Syst.","Muhammad Ibrar, Lei Wang 0005, Aamir Akbar, Mian Ahmad Jan, Nadir Shah, Shahbaz Akhtar Abid, Michael Segal 0001","Journal Articles","https://dblp.org/rec/journals/tcss/IbrarWAJSAS22","The social Internet of Things (IoT) (SIoT) helps to enable an autonomous interaction between the two architectures that have already been established: social networks and the IoT. SIoT also integrates the concepts of social networking and IoT into collaborative edge computing (CEC), the so-called CEC-based SIoT architecture. In closer proximity, IoT devices self-organize into a CEC-based SIoT computing cluster and provide social device-to-device (S-D2D) services, such as computation offloading, service discovery, and content delivery. In the CEC-based SIoT, however, cooperation based on social connections leads to a problem called social and spatial physical trade-off. This problem is also referred to as the mismatch problem, which arises because the spatial neighbors in the social layer cannot always be related. The spatial distance thus calls for additional multi-hop transmissions. This work presents a novel solution called 3-D-social identifier structure (3-D-SIS) model. The 3-D-SIS model is based on 3-D social space (3-D-SS) and considers social ties and physical connections (i.e., intra-neighbor) of the SIoT devices and utilizes a 3-D structure to evaluate that relationship. Moreover, it minimizes the end-to-end delay and communication cost to address the mismatch problem. To validate the performance of the (3-D-SIS) model, we use the real traces of social networks (INFOCOM06). The results show that the 3-D-SIS selects the best neighbor in S-D2D communication and improves performance in terms of end-to-end delay and throughput."
"A Comprehensive Skills Analysis of Novice Software Developers Working in the Professional Software Development Industry.","2022","Complex.","Imdad Ahmad Mian, Ijaz Ul Haq, Aamir Anwar, Roobaea Alroobaea, Syed Sajid Ullah, Fahad M. Almansour, Fazlullah Umar","Journal Articles","https://dblp.org/rec/journals/complexity/MianHAAUAU22","Measuring and evaluating a learner’s learning ability is always the focus of every person whose aim is to develop strategies and plans for their learners to improve the learning process. For example, classroom assessments, self-assessment using computer systems such as Intelligent Tutoring Systems (ITS), and other approaches are available. Assessment of metacognition is one of these techniques. Having the ability to evaluate and monitor one’s learning is known as metacognition. An individual can then propose adjustments to their learning process based on this assessment. By monitoring, improving, and planning their activities, learners who can manage their cognitive skills are better able to manage their knowledge about a particular subject. It is common knowledge that students’ metacognitive and self-assessment skills and abilities have been extensively studied, but no research has been carried out on the mistakes that novice developers make because they do not use their self-assessment abilities enough. This study aims to assess the metacognitive skills and abilities of novice software developers working in the industry and to describe the consequences of awareness of metacognition on their performance. In the proposed study, we experimented with novice software developers and collected data using Devskiller and a self-assessment log to analyze their use of self-regulation skills. The proposed study showed that when developers are asked to reflect upon their work, they become more informed about their habitual mistakes, and using a self-assessment log helps them highlight their repetitive mistakes and experiences which allows them to improve their performance on future tasks."
"ARTNet: Ai-Based Resource Allocation and Task Offloading in a Reconfigurable Internet of Vehicular Networks.","2022","IEEE Trans. Netw. Sci. Eng.","Muhammad Ibrar, Aamir Akbar, Syed Rooh Ullah Jan, Mian Ahmad Jan, Lei Wang 0005, Houbing Song, Nadir Shah","Journal Articles","https://dblp.org/rec/journals/tnse/IbrarAJJWSS22","The convergence of Software-Defined Networking (SDN) and Internet of Vehicular (IoV) integrated with Fog Computing (FC), known as Software Defined Vehicular based FC (SDV-F), has recently been established to take advantage of both paradigms and efficiently control the wireless networks. SDV-F tackles numerous problems, such as scalability, load-balancing, energy consumption, and security. It lags, however, in providing a promising approach to enable ultra-reliable and delay-sensitive applications with high vehicle mobility over SDV-F. We propose ARTNet, an AI-based Vehicle-to-Everything (V2X) framework for resource distribution and optimized communication using the SDV-F architecture. ARTNet offers ultra-reliable and low-latency communications, particularly in highly dynamic environments, which is still a challenge in IoV. ARTNet is composed of intelligent agents/controllers, to make decisions intelligently about (i) maximizing resource utilization at the fog layer, and (ii) minimizing the average end-to-end delay of time-critical IoV applications. Moreover, ARTNet is designed to assign a task to fog nodes based on their states. Our experimental results show that considering a dynamic IoV environment, ARTNet can efficiently distribute the fog layer tasks while minimizing the delay."
"AirPose: Multi-View Fusion Network for Aerial 3D Human Pose and Shape Estimation.","2022","IEEE Robotics Autom. Lett.","Nitin Saini, Elia Bonetto, Eric Price 0002, Aamir Ahmad, Michael J. Black","Journal Articles","https://dblp.org/rec/journals/ral/SainiBPAB22","In this letter, we present a novel markerless 3D human motion capture (MoCap) system for unstructured, outdoor environments that uses a team of autonomous unmanned aerial vehicles (UAVs) with on-board RGB cameras and computation. Existing methods are limited by calibrated cameras and off-line processing. Thus, we present the first method (AirPose) to estimate human pose and shape using images captured by multiple extrinsically uncalibrated flying cameras. AirPose itself calibrates the cameras relative to the person instead of relying on any pre-calibration. It uses distributed neural networks running on each UAV that communicate viewpoint-independent information with each other about the person (i.e., their 3D shape and articulated pose). The person’s shape and pose are parameterized using the SMPL-X body model, resulting in a compact representation, that minimizes communication between the UAVs. The network is trained using synthetic images of realistic virtual environments, and fine-tuned on a small set of real images. We also introduce an optimization-based post-processing method (AirPose$^{+}$) for offline applications that require higher MoCap quality. We make our method’s code and data available for research at https://github.com/robot-perception-group/AirPose. A video describing the approach and results is available at https://youtu.be/xLYe1TNHsfs."
"All-optical 40 channels regenerator based on four-wave mixing.","2022","Telecommun. Syst.","Salman Ghafoor, Muhammad Usama Khan, Aamir Gulistan, Ahmad Salman, Syed Mohammad Hassan Zaidi","Journal Articles","https://dblp.org/rec/journals/telsys/GhafoorKGSZ22","Abstract
        We have proposed a novel multi-channel regeneration scheme for wavelength division multiplexed systems, which is based on four wave mixing in a highly nonlinear fiber. A 40-channel wavelength division multiplexed signal having data rate of 10 Gbps per channel is divided into five groups. Each group is composed of eight channels and requires a single pump laser source and two segments of highly nonlinear fibers to regenerate the eight channels. Therefore, our proposed scheme requires four times lesser number of highly nonlinear fibers compared to the previously proposed techniques. The regeneration performance for all the forty channels is presented through bit error rate analysis at low optical signal to noise ratio of 15 dB. Simulation results show that an average improvement of 4.246 dB, 3.935 dB, 3.72 dB, 2.71 dB and 2.593 dB in receiver sensitivities has been observed for all the five groups of channels, respectively."
"Deep Learning-Based Forearm Subcutaneous Veins Segmentation.","2022","IEEE Access","Zaineb Shah, Syed Ayaz Ali Shah, Aamir Shahzad, Ahmad Fayyaz, Shoaib Khaliq, Ali Zahir, Goh Chuan Meng","Journal Articles","https://dblp.org/rec/journals/access/ShahSSFKZM22","In most of the medical treatments, intravenous catheterization is considered as a first crucial phase, in which health practitioners find the superficial vein to conduct blood sampling or medication procedures. In some patients these veins are hard to localize due to different physiological characteristics such as dark skin tone, scars, vein depth etc., which mostly results in multiple attempts for needle insertion. This causes pain, delayed treatment, bleeding, and even infections. To reduce these risks, an automated veins detection method is needed that can efficiently segment the veins and produce realistic results for cannulation purposes. For this purpose, many imaging modalities such as Photoacoustic, Trans-illumination, ultrasound, Near-Infrared etc. are used. Among these modalities Near-Infrared (NIR) imaging modality is considered most suitable due to its lower cost and non-ionizing nature. Over the past few years, subcutaneous veins localization using NIR have attracted increasing attention in the field of health care and biomedical engineering. Therefore, the proposed research work is based on NIR images for forearm subcutaneous veins segmentation. This paper presents a deep learning-based approach called Generative Adversarial Networks (GAN) for segmentation/localization of forearm veins. GANs have shown exciting results in the medical imaging field recently. These are used for unsupervised feature learning and image-to-image translation applications. These networks generate realistic results by learning data mapping from one state to another. Since GANs can produce state of the art results, therefore we have proposed a Pix2Pix GAN for segmentation of forearm veins. The proposed algorithm is trained and tested on forearm subcutaneous veins image dataset. The proposed model outperforms traditional approaches with the mean accuracy and sensitivity, values obtained are 0.971 and 0.862 respectively. The dice coefficient and Intersection over Union (IoU) score are respectively 0.962 and 0.936 which are better than the state-of-the-art methods."
"Deep Residual Reinforcement Learning based Autonomous Blimp Control.","2022","IROS","Yu Tang Liu, Eric Price 0002, Michael J. Black, Aamir Ahmad","Conference and Workshop Papers","https://dblp.org/rec/conf/iros/Liu0BA22","Blimps are well suited to perform long-duration aerial tasks as they are energy efficient, relatively silent and safe. To address the blimp navigation and control task, in previous work we developed a hardware and software-in-the-loop framework and a PID-based controller for large blimps in the presence of wind disturbance. However, blimps have a deformable structure and their dynamics are inherently non-linear and time-delayed, making PID controllers difficult to tune. Thus, often resulting in large tracking errors. Moreover, the buoyancy of a blimp is constantly changing due to variations in ambient temperature and pressure. To address these issues, in this paper we present a learning-based framework based on deep residual reinforcement learning (DRRL), for the blimp control task. Within this framework, we first employ a PID controller to provide baseline performance. Subsequently, the DRRL agent learns to modify the PID decisions by interaction with the environment. We demonstrate in simulation that DRRL agent consistently improves the PID performance. Through rigorous simulation experiments, we show that the agent is robust to changes in wind speed and buoyancy. In real-world experiments, we demonstrate that the agent, trained only in simulation, is sufficiently robust to control an actual blimp in windy conditions. We openly provide the source code of our approach at https://github.com/robot-perception-group/AutonomousBlimpDRL. Video demonstration is provided at https://youtu.be/EMC4KnlH0yI."
"PS-InSAR Based Monitoring of Land Subsidence by Groundwater Extraction for Lahore Metropolitan City, Pakistan.","2022","Remote. Sens.","Muhammad Afaq Hussain, Zhanlong Chen, Ying Zheng, Muhammad Shoaib, Junwei Ma, Ijaz Ahmad, Aamir Asghar, Junaid Khan","Journal Articles","https://dblp.org/rec/journals/remotesensing/HussainCZSMAAK22","Groundwater dynamics caused by extraction and recharge are one of the primary causes of subsidence in the urban environment. Lahore is the second largest metropolitan city in Pakistan. The rapid expansion of this urban area due to high population density has increased the demand for groundwater to meet commercial and household needs. Land subsidence due to inadequate groundwater extraction has long been a concern in Lahore. This paper aims to present the persistent scatterer interferometry synthetic aperture radar (PS-InSAR) technique for monitoring the recent land subsidence in Lahore, based on the Sentinel-1 data obtained from January 2020 to December 2021. PS-InSAR techniques are very efficient and cost-effective, determining land subsidence and providing useful results. Areas of high groundwater discharge are prone to high subsidence of −110 mm, while the surroundings show an uplifting of +21 mm during the study period. The PS-InSAR study exposes the subsidence area in detail, particularly when the subsoil is characterized by alluvial and clay deposits and large building structures. This type of observation is quite satisfactory and similar to ground-based surface deformation pertinent to a high subsidence rate. Results will enable more effective urban planning, land infrastructure building, and risk assessment related to subsidence."
"Perception-driven Formation Control of Airships.","2022","CoRR","Eric Price 0002, Michael J. Black, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2209-13040","—For tracking and motion capture (MoCap) of animals in their natural habitat, a formation of safe and silent aerial platforms, such as airships with on-board cameras, is well suited. However, unlike multi-rotors, airships are severely motion constrained and affected by ambient wind. Their orientation and ﬂight direction are also tightly coupled. Therefore, state-of-the-art MPC-based formation control methods for perception tasks are not directly applicable for a team of airships. In this paper, we address this problem by ﬁrst exploiting a periodic relationship between the airspeed of an airship and its distance to the subject. We use it to derive analytical and numeric solutions that satisfy the MoCap perception constraints. Based on this, we develop an MPC-based formation controller. We performed detailed analysis of our solution, including the effects of changing physical parameters (like angle of attack and pitch angle) on it. Extensive simulation experiments, comparing results for different formation sizes, different wind conditions and various subject speeds, are presented. A demonstration of our method on a real airship is also included. We have released all of our source code at https://github.com/robot-perception-group/Airship-MPC. A video describing our approach and results can be watched at https://youtu.be/ihS0 VRD kk"
"SmartMocap: Joint Estimation of Human and Camera Motion using Uncalibrated RGB Cameras.","2022","CoRR","Nitin Saini, Chun-Hao P. Huang, Michael J. Black, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2209-13906","Markerless human motion capture (mocap) from multiple RGB cameras is a widely studied problem. Existing methods either need calibrated cameras or calibrate them relative to a static camera, which acts as the reference frame for the mocap system. The calibration step has to be done a priori for every capture session, which is a tedious process, and re-calibration is required whenever cameras are intentionally or accidentally moved. In this letter, we propose a mocap method which uses multiple static and moving extrinsically uncalibrated RGB cameras. The key components of our method are as follows. First, since the cameras and the subject can move freely, we select the ground plane as a common reference to represent both the body and the camera motions unlike existing methods which represent bodies in the camera coordinate system. Second, we learn a probability distribution of short human motion sequences ($\sim$1 sec) relative to the ground plane and leverage it to disambiguate between the camera and human motion. Third, we use this distribution as a motion prior in a novel multi-stage optimization approach to fit the SMPL human body model and the camera poses to the human body keypoints on the images. Finally, we show that our method can work on a variety of datasets ranging from aerial cameras to smartphones. It also gives more accurate results compared to the state-of-the-art on the task of monocular human mocap with a static camera."
"iRotate: Active Visual SLAM for Omnidirectional Robots.","2022","Robotics Auton. Syst.","Elia Bonetto, Pascal Goldschmid, Michael Pabst, Michael J. Black, Aamir Ahmad","Journal Articles","https://dblp.org/rec/journals/ras/BonettoGPBA22",""
"Configuration Detection of Grounding Grid: Static Electric Field Based Nondestructive Technique.","2021","IEEE Access","Aamir Qamar, Shahid Iqbal, Sadiq Ahmad, Abbas Z. Kouzani, M. A. Parvez Mahmud","Journal Articles","https://dblp.org/rec/journals/access/QamarIAKM21","Grounding grid configuration which, is key to its fault diagnosis, changes continuously with the extension in a substation. Furthermore, older substations grounding grid configurations are unknown. Existing literature regarding configuration detection mainly accounts for the magnetic field that required a gradient to locate the grounding conductor. The gradient of raw measurement in the substation vicinity enhances electromagnetic noise and distorts the results. Therefore, in this paper, we have developed a new algorithm, Configuration Detection of Grounding Grid (CDGG) based on the static electric field and the concept of ordered pairs to draw the configuration of the unknown grounding grid. Unlike, the practiced magnetic field, the electric field does not require a gradient. The maximum electric field value indicates the location of a grounding conductor. The connection between nodes is verified by measuring the electric field on the circle. Furthermore, the proposed algorithm also locates any diagonal conductor in the configuration. Mathematical reasoning and simulation results illustrate that our proposed algorithm is feasible to draw the configuration of the unknown grounding grid."
"Modified EWMA control chart for transformed gamma data.","2021","Commun. Stat. Simul. Comput.","Aamir Saghir, Liaquat Ahmad, Muhammad Aslam 0002","Journal Articles","https://dblp.org/rec/journals/cssc/SaghirAA21","Abstract The current article, design a control chart using a modified exponentially weighted moving average statistic (using transformation) which further enhance the sensitivity of the EWMA chart under the assumption that the quality characteristic of interest follows the gamma distribution. The necessary measures are determined to design the proposed chart and to evaluate its performance for in-control and out-of-control situations. The performance comparison of the proposed chart in terms of average run length is made with two existing control charts. The results of the study are shown that the proposed chart is an efficient chart than its two existing competitive control charts for detecting out-of-control process quickly. The application of the proposed chart is given with the help of an industrial example."
"Predicting the Direction Movement of Financial Time Series Using Artificial Neural Network and Support Vector Machine.","2021","Complex.","Muhammad Ali 0003, Dost Muhammad Khan, Muhammad Aamir 0003, Amjad Ali 0005, Zubair Ahmad","Journal Articles","https://dblp.org/rec/journals/complexity/AliKAAA21","Prediction of financial time series such as stock and stock indexes has remained the main focus of researchers because of its composite nature and instability in almost all of the developing and advanced countries. The main objective of this research work is to predict the direction movement of the daily stock prices index using the artificial neural network (ANN) and support vector machine (SVM). The datasets utilized in this study are the KSE-100 index of the Pakistan stock exchange, Korea composite stock price index (KOSPI), Nikkei 225 index of the Tokyo stock exchange, and Shenzhen stock exchange (SZSE) composite index for the last ten years that is from 2011 to 2020. To build the architect of a single layer ANN and SVM model with linear, radial basis function (RBF), and polynomial kernels, different technical indicators derived from the daily stock trading, such as closing, opening, daily high, and daily low prices and used as input layers. Since both the ANN and SVM models were used as classifiers; therefore, accuracy and F-score were used as performance metrics calculated from the confusion matrix. It can be concluded from the results that ANN performs better than SVM model in terms of accuracy and F-score to predict the direction movement of the KSE-100 index, KOSPI index, Nikkei 225 index, and SZSE composite index daily closing price movement."
"SDN-Enabled Adaptive and Reliable Communication in IoT-Fog Environment Using Machine Learning and Multiobjective Optimization.","2021","IEEE Internet Things J.","Aamir Akbar, Muhammad Ibrar, Mian Ahmad Jan, Ali Kashif Bashir, Lei Wang 0005","Journal Articles","https://dblp.org/rec/journals/iotj/AkbarIJBW21",""
"SpoofCatch: A Client-Side Protection Tool Against Phishing Attacks.","2021","IT Prof.","Wilayat Khan, Aakash Ahmad, Aamir Qamar, Muhammad Kamran, Muhammad Altaf","Journal Articles","https://dblp.org/rec/journals/itpro/KhanAQKA21","To protect against web spoofing attacks, most antiphishing solutions in the literature either escape certain attack patterns or are based on complex sets of parameters to identify phishing attacks or suffer from both. In this article, we propose that phishing attacks can be prevented by simply relying on an overall visual appearance of the web page that the user sees. To realize our claim, we propose a client-side protection mechanism based on visual similarity of web pages and implement our mechanism as a browser extension, dubbed SpoofCatch. For similarity comparison between genuine and phished web pages, four similarity algorithms have been implemented and integrated in the extension. To evaluate the solution, large scale and extensive experiments have been conducted that demonstrate SpoofCatch can capture all phishing attacks with acceptable overhead."
"Active Visual SLAM with Independently Rotating Camera.","2021","ECMR","Elia Bonetto, Pascal Goldschmid, Michael J. Black, Aamir Ahmad","Conference and Workshop Papers","https://dblp.org/rec/conf/ecmr/BonettoGBA21","In active Visual-SLAM (V-SLAM), a robot relies on the information retrieved by its cameras to control its own movements for autonomous mapping of the environment. Cameras are usually statically linked to the robot’s body, limiting the extra degrees of freedom for visual information acquisition. In this work, we overcome the aforementioned problem by introducing and leveraging an independently rotating camera on the robot base. This enables us to continuously control the heading of the camera, obtaining the desired optimal orientation for active V-SLAM, without rotating the robot itself. However, this additional degree of freedom introduces additional estimation uncertainties, which need to be accounted for. We do this by extending our robot’s state estimate to include the camera state and jointly estimate the uncertainties. We develop our method based on a state-of-the-art active V-SLAM approach for omnidirectional robots and evaluate it through rigorous simulation and real robot experiments. We obtain more accurate maps, with lower energy consumption, while maintaining the benefits of the active approach with respect to the baseline. We also demonstrate how our method easily generalizes to other non-omnidirectional robotic platforms, which was a limitation of the previous approach. Code and implementation details are provided as open-source."
"Autonomous Blimp Control using Deep Reinforcement Learning.","2021","CoRR","Yu Tang Liu, Eric Price 0002, Pascal Goldschmid, Michael J. Black, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2109-10719","Aerial robot solutions are becoming ubiquitous for an increasing number of tasks. Among the various types of aerial robots, blimps are very well suited to perform long-duration tasks while being energy efficient, relatively silent and safe. To address the blimp navigation and control task, in our recent work, we have developed a software-in-the-loop simulation and a PID-based controller for large blimps in the presence of wind disturbance. However, blimps have a deformable structure and their dynamics are inherently non-linear and time-delayed, often resulting in large trajectory tracking errors. Moreover, the buoyancy of a blimp is constantly changing due to changes in the ambient temperature and pressure. In the present paper, we explore a deep reinforcement learning (DRL) approach to address these issues. We train only in simulation, while keeping conditions as close as possible to the real-world scenario. We derive a compact state representation to reduce the training time and a discrete action space to enforce control smoothness. Our initial results in simulation show a significant potential of DRL in solving the blimp control task and robustness against moderate wind and parameter uncertainty. Extensive experiments are presented to study the robustness of our approach. We also openly provide the source code of our approach."
"Collaborative Mapping of Archaeological Sites Using Multiple UAVs.","2021","IAS","Manthan Patel, Aditya Bandopadhyay, Aamir Ahmad","Conference and Workshop Papers","https://dblp.org/rec/conf/ias/PatelBA21",""
"Comparative analysis of machine learning approaches to analyze and predict the COVID-19 outbreak.","2021","PeerJ Comput. Sci.","Muhammad Naeem, Jian Yu, Muhammad Aamir 0003, Sajjad Ahmad Khan, Olayinka Adeleye, Zardad Khan","Journal Articles","https://dblp.org/rec/journals/peerj-cs/NaeemYAKAK21","Background Forecasting the time of forthcoming pandemic reduces the impact of diseases by taking precautionary steps such as public health messaging and raising the consciousness of doctors. With the continuous and rapid increase in the cumulative incidence of COVID-19, statistical and outbreak prediction models including various machine learning (ML) models are being used by the research community to track and predict the trend of the epidemic, and also in developing appropriate strategies to combat and manage its spread. Methods In this paper, we present a comparative analysis of various ML approaches including Support Vector Machine, Random Forest, K-Nearest Neighbor and Artificial Neural Network in predicting the COVID-19 outbreak in the epidemiological domain. We first apply the autoregressive distributed lag (ARDL) method to identify and model the short and long-run relationships of the time-series COVID-19 datasets. That is, we determine the lags between a response variable and its respective explanatory time series variables as independent variables. Then, the resulting significant variables concerning their lags are used in the regression model selected by the ARDL for predicting and forecasting the trend of the epidemic. Results Statistical measures—Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and Symmetric Mean Absolute Percentage Error (SMAPE)—are used for model accuracy. The values of MAPE for the best-selected models for confirmed, recovered and deaths cases are 0.003, 0.006 and 0.115, respectively, which falls under the category of highly accurate forecasts. In addition, we computed 15 days ahead forecast for the daily deaths, recovered, and confirm patients and the cases fluctuated across time in all aspects. Besides, the results reveal the advantages of ML algorithms for supporting the decision-making of evolving short-term policies."
"Control charts for the shape parameter of reflected power function distribution under classical estimators.","2021","Qual. Reliab. Eng. Int.","Azam Zaka, Ahmad Saeed Akhter, Riffat Jabeen, Aamir Sanaullah","Journal Articles","https://dblp.org/rec/journals/qre/ZakaAJS21","AbstractThe reflected power function distribution (RPFD) has applications in the fields of reliability engineering and survival analysis. To identify and remove the variation in different reliability processes and also to monitor the reliability of machines where the number of errors follows RPFD, we develop control charts to keep the process in control. A memory less control chart like a Shewhart control chart, and two memory‐based control charts like an exponentially weighted moving average (EWMA) control chart and a hybrid exponentially weighted moving average (HEWMA) control chart are discussed and compared with each other. Proposal of these control charts is based on two different estimators, the percentile estimator (PE) and the modified maximum likelihood estimator (MMLE). This study shows that an HEWMA control chart based on PE performs better than PE‐based Shewhart and EWMA control charts, as well as MMLE‐based Shewhart, EWMA, and HEWMA control charts."
"Edge Intelligence in Softwarized 6G: Deep Learning-enabled Network Traffic Predictions.","2021","GLOBECOM","Shah Zeb, Muhammad Ahmad Rathore, Aamir Mahmood, Syed Ali Hassan 0001, JongWon Kim 0001, Mikael Gidlund","Conference and Workshop Papers","https://dblp.org/rec/conf/globecom/ZebRMH0G21","The 6G vision is envisaged to enable agile network expansion and rapid deployment of new on-demand microservices (e.g., visibility services for data traffic management, mobile edge computing services) closer to the network’s edge IoT devices. However, providing one of the critical features of network visibility services, i.e., data flow prediction in the network, is challenging at the edge devices within a dynamic cloud-native environment as the traffic flow characteristics are random and sporadic. To provide the AI-native services for the 6G vision, we propose a novel edge-native framework to provide an intelligent prognosis technique for data traffic management in this paper. The prognosis model uses long short-term memory (LSTM)-based encoder-decoder deep learning, which we train on real time-series multivariate data records collected from the edge µ-boxes of a selected testbed network. Our result accurately predicts the statistical characteristics of data traffic and verifies the trained model against the ground truth observations. Moreover, we validate our novel framework with two performance metrics for each feature of the multivariate data."
"Knowledge and Trust Nexus Support the Link Among Six-sigma and Project Success: A Case of Developing Country.","2021","IDAACS","Asadullah, Wajid Shakeel Ahmad, Rao Aamir Khan","Conference and Workshop Papers","https://dblp.org/rec/conf/idaacs/AsadullahAK21","The fundamental purpose of this study is to check the impact of six sigma on project success by introducing the knowledge and trust nexus for engineering projects. The sample size of the study is 235 respondents and data is collected from the engineering industries through convenience sampling technique. The data collected is then analyzed by applying the structural equation modeling (SEM) technique in Smart-PLS in order to examine the relationships among observed variables. The outcome confirms the sharing of knowledge within the employees is directly linked to the project success, which align with the previous studies. Moreover, sharing of knowledge will help the employee to more learning and enhance their performance to achieve the project goals and objectives which leads to the success of the project. The outcomes also demonstrate the moderating role of trust between the six sigma and knowledge sharing. The study is unique in its scope and implications as the focus is upon empirical investigation of the impact of application of six sigma on project success in the context of developing economy like Pakistan."
"LightIoT: Lightweight and Secure Communication for Energy-Efficient IoT in Health Informatics.","2021","IEEE Trans. Green Commun. Netw.","Mian Ahmad Jan, Fazlullah Khan, Spyridon Mastorakis, Muhammad Adil 0002, Aamir Akbar, Nicholas Stergiou","Journal Articles","https://dblp.org/rec/journals/tgcn/JanKMAAS21","Internet of Things (IoT) is considered as a key enabler of health informatics. IoT-enabled devices are used for in-hospital and in-home patient monitoring to collect and transfer biomedical data pertaining to blood pressure, electrocardiography (ECG), blood sugar levels, body temperature, etc. Among these devices, wearables have found their presence in a wide range of healthcare applications. These devices generate data in real-time and transmit them to nearby gateways and remote servers for processing and visualization. The data transmitted by these devices are vulnerable to a range of adversarial threats, and as such, privacy and integrity need to be preserved. In this paper, we present LightIoT, a lightweight and secure communication approach for data exchanged among the devices of a healthcare infrastructure. LightIoT operates in three phases: initialization, pairing, and authentication. These phases ensure the reliable transmission of data by establishing secure sessions among the communicating entities (wearables, gateways and a remote server). Statistical results exhibit that our scheme is lightweight, robust, and resilient against a wide range of adversarial attacks and incurs much lower computational and communication overhead for the transmitted data in the presence of existing approaches."
"MS UNet: Multi-scale 3D UNet for Brain Tumor Segmentation.","2021","BrainLes@MICCAI","Parvez Ahmad, Saqib Qamar, Linlin Shen, Syed Qasim Afser Rizvi, Aamir Ali, Girija Chetty","Conference and Workshop Papers","https://dblp.org/rec/conf/brainles-ws/AhmadQSRAC21",""
"Natural Disasters Intensity Analysis and Classification Based on Multispectral Images Using Multi-Layered Deep Convolutional Neural Network.","2021","Sensors","Muhammad Aamir 0007, Tariq Ali, Muhammad Irfan 0008, Ahmad Shaf, Muhammad Zeeshan Azam, Adam Glowacz, Frantisek Brumercik, Witold Glowacz, Samar M. Alqhtani, Saifur Rahman","Journal Articles","https://dblp.org/rec/journals/sensors/AamirAISAGBGAR21","Natural disasters not only disturb the human ecological system but also destroy the properties and critical infrastructures of human societies and even lead to permanent change in the ecosystem. Disaster can be caused by naturally occurring events such as earthquakes, cyclones, floods, and wildfires. Many deep learning techniques have been applied by various researchers to detect and classify natural disasters to overcome losses in ecosystems, but detection of natural disasters still faces issues due to the complex and imbalanced structures of images. To tackle this problem, we propose a multilayered deep convolutional neural network. The proposed model works in two blocks: Block-I convolutional neural network (B-I CNN), for detection and occurrence of disasters, and Block-II convolutional neural network (B-II CNN), for classification of natural disaster intensity types with different filters and parameters. The model is tested on 4428 natural images and performance is calculated and expressed as different statistical values: sensitivity (SE), 97.54%; specificity (SP), 98.22%; accuracy rate (AR), 99.92%; precision (PRE), 97.79%; and F1-score (F1), 97.97%. The overall accuracy for the whole model is 99.92%, which is competitive and comparable with state-of-the-art algorithms."
"Real Time Multipurpose Smart Waste Classification Model for Efficient Recycling in Smart Cities Using Multilayer Convolutional Neural Network and Perceptron.","2021","Sensors","Ali Usman Gondal, Muhammad Imran Sadiq, Tariq Ali, Muhammad Irfan 0008, Ahmad Shaf, Muhammad Aamir 0007, Muhammad Shoaib, Adam Glowacz, Ryszard Tadeusiewicz, Eliasz Kantoch","Journal Articles","https://dblp.org/rec/journals/sensors/GondalSAISASGTK21","Urbanization is a big concern for both developed and developing countries in recent years. People shift themselves and their families to urban areas for the sake of better education and a modern lifestyle. Due to rapid urbanization, cities are facing huge challenges, one of which is waste management, as the volume of waste is directly proportional to the people living in the city. The municipalities and the city administrations use the traditional wastage classification techniques which are manual, very slow, inefficient and costly. Therefore, automatic waste classification and management is essential for the cities that are being urbanized for the better recycling of waste. Better recycling of waste gives the opportunity to reduce the amount of waste sent to landfills by reducing the need to collect new raw material. In this paper, the idea of a real-time smart waste classification model is presented that uses a hybrid approach to classify waste into various classes. Two machine learning models, a multilayer perceptron and multilayer convolutional neural network (ML-CNN), are implemented. The multilayer perceptron is used to provide binary classification, i.e., metal or non-metal waste, and the CNN identifies the class of non-metal waste. A camera is placed in front of the waste conveyor belt, which takes a picture of the waste and classifies it. Upon successful classification, an automatic hand hammer is used to push the waste into the assigned labeled bucket. Experiments were carried out in a real-time environment with image segmentation. The training, testing, and validation accuracy of the purposed model was 0.99% under different training batches with different input features."
"Simulation and Control of Deformable Autonomous Airships in Turbulent Wind.","2021","IAS","Eric Price 0002, Yu Tang Liu, Michael J. Black, Aamir Ahmad","Conference and Workshop Papers","https://dblp.org/rec/conf/ias/PriceLBA21","AbstractFixed wing and multirotor UAVs are common in the field of robotics. Solutions for simulation and control of these vehicles are ubiquitous. This is not the case for airships, a simulation of which needs to address unique properties, i) dynamic deformation in response to aerodynamic and control forces, ii) high susceptibility to wind and turbulence at low airspeed, iii) high variability in airship designs regarding placement, direction and vectoring of thrusters and control surfaces. We present a flexible framework for modeling, simulation and control of airships. It is based on Robot operating system (ROS), simulation environment (Gazebo) and commercial off the shelf (COTS) electronics, all of which are open source. Based on simulated wind and deformation, we predict substantial effects on controllability which are verified in real-world flight experiments. All our code is shared as open source, for the benefit of the community and to facilitate lighter-than-air vehicle (LTAV) research. (Source code:https://github.com/robot-perception-group/airship_simulation.)"
"iRotate: Active Visual SLAM for Omnidirectional Robots.","2021","CoRR","Elia Bonetto, Pascal Goldschmid, Michael Pabst, Michael J. Black, Aamir Ahmad","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2103-11641",""
