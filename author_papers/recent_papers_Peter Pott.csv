"title","year","venue","authors","type","url","abstract"
"Manipulating Embeddings of Stable Diffusion Prompts.","2024","IJCAI","Niklas Deckers, Julia Peters, Martin Potthast","Conference and Workshop Papers","https://dblp.org/rec/conf/ijcai/DeckersPP24","Prompt engineering is still the primary way for users of generative text-to-image models to manipulate generated images in a targeted way. Based on treating the model as a continuous function and by passing gradients between the image space and the prompt embedding space, we propose and analyze a new method to directly manipulate the embedding of a prompt instead of the prompt text. We then derive three practical interaction tools to support users with image generation: (1) Optimization of a metric defined in the image space that measures, for example, the image style. (2) Supporting a user in creative tasks by allowing them to navigate in the image space along a selection of directions of ""near"" prompt embeddings. (3) Changing the embedding of the prompt to include information that a user has seen in a particular seed but has difficulty describing in the prompt. Compared to prompt engineering, user-driven prompt embedding manipulation enables a more fine-grained, targeted control that integrates a user's intentions. Our user study shows that our methods are considered less tedious and that the resulting images are often preferred."
"3D Reconstruction of Forearm Veins Using NIR-Based Stereovision and Deep Learning.","2023","CBMS","Jan Liu, Flakë Bajraktari, Regine Rausch, Peter P. Pott","Conference and Workshop Papers","https://dblp.org/rec/conf/cbms/LiuBRP23","In this paper, the development of a cost-effective assistance system for venipuncture is presented. The system locates forearm veins through near-infrared imaging, depth estimation, deep learning segmentation, and 3D reconstruction. A single-board computer was integrated with two infrared cameras and two 760 nm near-infrared (NIR) LEDs to capture and process stereo images. The depth estimation was achieved through stereo triangulation. A deep learning model based on the U-Net architecture with an attention mechanism and a training dataset of 900 images from 40 participants was used for vein segmentation. Depth information and segmented veins were combined to enable a 3D visualization of the veins. The results show a Jaccard-Score of 92.80 % for vein segmentation and an average reprojection error of 0.48 pixels for the 3D reconstruction."
"Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models.","2023","Trans. Mach. Learn. Res.","Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S. Iyer, Anders Andreassen, Andrea Madotto, Andrea Santilli, Andreas Stuhlmüller, Andrew M. Dai, Andrew La, Andrew K. Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakas, B. Ryan Roberts, Bao Sheng Loe, Barret Zoph, Bartlomiej Bojanowski, Batuhan Özyurt, Behnam Hedayatnia, Behnam Neyshabur, Benjamin Inden, Benno Stein 0001, Berk Ekmekci, Bill Yuchen Lin, Blake Howald, Bryan Orinion, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta, Cèsar Ferri Ramírez, Chandan Singh, Charles Rathkopf, Chenlin Meng, Chitta Baral, Chiyu Wu, Chris Callison-Burch, Chris Waites, Christian Voigt, Christopher D. Manning, Christopher Potts, Cindy Ramirez, Clara E. Rivera, Clemencia Siro, Colin Raffel, Courtney Ashcraft, Cristina Garbacea, Damien Sileo, Dan Garrette, Dan Hendrycks, Dan Kilman, Dan Roth, Daniel Freeman, Daniel Khashabi, Daniel Levy, Daniel Moseguí González, Danielle Perszyk, Danny Hernandez, Danqi Chen 0001, Daphne Ippolito, Dar Gilboa, David Dohan, David Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli, Denis Emelin, Denis Kleyko, Deniz Yuret, Derek Chen, Derek Tam, Dieuwke Hupkes, Diganta Misra, Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Dylan Schrader, Ekaterina Shutova, Ekin Dogus Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodolà, Emma Lam, Eric Chu, Eric Tang, Erkut Erdem, Ernie Chang, Ethan A. Chi, Ethan Dyer, Ethan J. Jerzak, Ethan Kim, Eunice Engefu Manyasi, Evgenii Zheltonozhskii, Fanyue Xia, Fatemeh Siar, Fernando Martínez-Plumed, Francesca Happé, François Chollet, Frieda Rong, Gaurav Mishra, Genta Indra Winata, Gerard de Melo, Germán Kruszewski, Giambattista Parascandolo, Giorgio Mariani, Gloria Wang, Gonzalo Jaimovitch-López, Gregor Betz, Guy Gur-Ari, Hana Galijasevic, Hannah Kim 0010, Hannah Rashkin, Hannaneh Hajishirzi, Harsh Mehta, Hayden Bogar, Henry Shevlin, Hinrich Schütze, Hiromu Yakura, Hongming Zhang 0009, Hugh Mee Wong, Ian Ng, Isaac Noble, Jaap Jumelet, Jack Geissinger, Jackson Kernion, Jacob Hilton, Jaehoon Lee 0001, Jaime Fernández Fisac, James B. Simon, James Koppel, James Zheng, James Zou 0001, Jan Kocon, Jana Thompson, Janelle Wingfield, Jared Kaplan, Jarema Radom, Jascha Sohl-Dickstein, Jason Phang, Jason Wei, Jason Yosinski, Jekaterina Novikova, Jelle Bosscher, Jennifer Marsh, Jeremy Kim, Jeroen Taal, Jesse H. Engel, Jesujoba Alabi, Jiacheng Xu, Jiaming Song, Jillian Tang, Joan Waweru, John Burden, John Miller 0001, John U. Balis, Jonathan Batchelder, Jonathan Berant, Jörg Frohberg, Jos Rozen, José Hernández-Orallo, Joseph Boudeman, Joseph Guerr, Joseph Jones, Joshua B. Tenenbaum, Joshua S. Rule, Joyce Chua, Kamil Kanclerz, Karen Livescu, Karl Krauth, Karthik Gopalakrishnan 0001, Katerina Ignatyeva, Katja Markert, Kaustubh D. Dhole, Kevin Gimpel, Kevin Omondi, Kory Mathewson, Kristen Chiafullo, Ksenia Shkaruta, Kumar Shridhar, Kyle McDonell, Kyle Richardson 0001, Laria Reynolds, Leo Gao, Li Zhang 0039, Liam Dugan, Lianhui Qin, Lidia Contreras Ochando, Louis-Philippe Morency, Luca Moschella, Lucas Lam, Lucy Noble, Ludwig Schmidt, Luheng He, Luis Oliveros Colón, Luke Metz, Lütfi Kerem Senel, Maarten Bosma, Maarten Sap, Maartje ter Hoeve, Maheen Farooqi, Manaal Faruqui, Mantas Mazeika, Marco Baturan, Marco Marelli, Marco Maru, María José Ramírez-Quintana, Marie Tolkiehn, Mario Giulianelli, Martha Lewis, Martin Potthast, Matthew L. Leavitt, Matthias Hagen, Mátyás Schubert, Medina Baitemirova, Melody Arnaud, Melvin McElrath, Michael A. Yee, Michael Cohen, Michael Gu, Michael I. Ivanitskiy, Michael Starritt, Michael Strube 0001, Michal Swedrowski, Michele Bevilacqua, Michihiro Yasunaga, Mihir Kale, Mike Cain, Mimee Xu, Mirac Suzgun, Mitch Walker, Mo Tiwari, Mohit Bansal, Moin Aminnaseri, Mor Geva, Mozhdeh Gheini, Mukund Varma T., Nanyun Peng, Nathan A. Chi, Nayeon Lee, Neta Gur-Ari Krakover, Nicholas Cameron 0001, Nicholas Roberts, Nick Doiron, Nicole Martinez, Nikita Nangia, Niklas Deckers, Niklas Muennighoff, Nitish Shirish Keskar, Niveditha Iyer, Noah Constant, Noah Fiedel, Nuan Wen, Oliver Zhang, Omar Agha, Omar Elbaghdadi, Omer Levy, Owain Evans, Pablo Antonio Moreno Casares, Parth Doshi, Pascale Fung, Paul Pu Liang, Paul Vicol, Pegah Alipoormolabashi, Peiyuan Liao, Percy Liang, Peter Chang, Peter Eckersley, Phu Mon Htut, Pinyu Hwang, Piotr Milkowski, Piyush Patil, Pouya Pezeshkpour, Priti Oli, Qiaozhu Mei, Qing Lyu 0001, Qinlang Chen 0001, Rabin Banjade, Rachel Etta Rudolph, Raefer Gabriel, Rahel Habacker, Ramon Risco, Raphaël Millière, Rhythm Garg, Richard Barnes 0002, Rif A. Saurous, Riku Arakawa, Robbe Raymaekers, Robert Frank 0001, Rohan Sikand, Roman Novak, Roman Sitelew, Ronan LeBras, Rosanne Liu, Rowan Jacobs, Rui Zhang 0037, Ruslan Salakhutdinov, Ryan Chi, Ryan Lee, Ryan Stovall, Ryan Teehan, Rylan Yang, Sahib Singh, Saif M. Mohammad, Sajant Anand, Sam Dillavou, Sam Shleifer, Sam Wiseman, Samuel Gruetter, Samuel R. Bowman, Samuel S. Schoenholz, Sanghyun Han, Sanjeev Kwatra, Sarah A. Rous, Sarik Ghazarian, Sayan Ghosh 0004, Sean Casey, Sebastian Bischoff 0001, Sebastian Gehrmann, Sebastian Schuster, Sepideh Sadeghi, Shadi Hamdan, Sharon Zhou, Shashank Srivastava, Sherry Shi, Shikhar Singh, Shima Asaadi, Shixiang Shane Gu, Shubh Pachchigar, Shubham Toshniwal, Shyam Upadhyay, Shyamolima (Shammie) Debnath, Siamak Shakeri, Simon Thormeyer, Simone Melzi, Siva Reddy, Sneha Priscilla Makini, Soo-Hwan Lee, Spencer Torene, Sriharsha Hatwar, Stanislas Dehaene, Stefan Divic, Stefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad, Steven T. Piantadosi, Stuart M. Shieber, Summer Misherghi, Svetlana Kiritchenko, Swaroop Mishra, Tal Linzen, Tal Schuster, Tao Li 0039, Tao Yu 0009, Tariq Ali, Tatsu Hashimoto, Te-Lin Wu, Théo Desbordes, Theodore Rothschild, Thomas Phan, Tianle Wang 0009, Tiberius Nkinyili, Timo Schick, Timofei Kornev, Titus Tunduny, Tobias Gerstenberg, Trenton Chang, Trishala Neeraj, Tushar Khot, Tyler Shultz, Uri Shaham 0002, Vedant Misra, Vera Demberg, Victoria Nyamai, Vikas Raunak, Vinay V. Ramasesh, Vinay Uday Prabhu, Vishakh Padmakumar, Vivek Srikumar, William Fedus, William Saunders, William Zhang, Wout Vossen, Xiang Ren 0001, Xiaoyu Tong, Xinran Zhao, Xinyi Wu, Xudong Shen, Yadollah Yaghoobzadeh, Yair Lakretz, Yangqiu Song, Yasaman Bahri, Yejin Choi 0001, Yichi Yang, Yiding Hao, Yifu Chen, Yonatan Belinkov, Yu Hou, Yufang Hou 0001, Yuntao Bai, Zachary Seid, Zhuoye Zhao, Zijian Wang 0002, Zijie J. Wang, Zirui Wang, Ziyi Wu","Journal Articles","https://dblp.org/rec/journals/tmlr/SrivastavaRRSAF23","Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit""breakthrough""behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting."
"CNN-Based Intention Recognition Using Body-Worn Inertial Measurement Units.","2023","CBMS","Flakë Bajraktari, Nikolas Roßkopf, Peter P. Pott","Conference and Workshop Papers","https://dblp.org/rec/conf/cbms/BajraktariRP23","This study explores the potential of using a sensor system and deep learning algorithm for automatic recognition and classification of human movement intentions to enhance the control of active orthopedic aids such as orthoses, prostheses, and exoskeletons. The sensor system consists of four inertial measurement units (IMU) attached to the thighs, lower back, and chest of a person, measuring acceleration and rotational velocity in three axes each. A dataset was generated from 20 healthy individuals performing various movements from a standing position, and preprocessed and segmented into time windows. The data was fed into a convolutional neural network (CNN) capable of classifying the time windows into seven classes. The network achieved a classification accuracy of up to 82 %. The results demonstrate the potential of the proposed system for successful application in the control of assistance systems, which can improve the operability and effectiveness of orthopedic aids."
"Lexical Semantics with Large Language Models: A Case Study of English ""break"".","2023","EACL","Erika Petersen, Christopher Potts","Conference and Workshop Papers","https://dblp.org/rec/conf/eacl/PetersenP23","Large neural language models (LLMs) can be powerful tools for research in lexical semantics. We illustrate this potential using the English verb “break”, which has numerous senses and appears in a wide range of syntactic frames. We show that LLMs capture known sense distinctions and can be used to identify informative new sense combinations for further analysis. More generally, we argue that LLMs are aligned with lexical semantic theories in providing high-dimensional, contextually modulated representations, but LLMs’ lack of discrete features and dependence on usage-based data offer a genuinely new perspective on traditional problems in lexical semantics."
"Manipulating Embeddings of Stable Diffusion Prompts.","2023","Zenodo","Niklas Deckers, Julia Peters, Martin Potthast","Data and Artifacts","https://dblp.org/rec/data/10/DeckersPP23","Prompt engineering is still the primary way for users of generative text-to-image models to manipulate generated images in a targeted way. Based on treating the model as a continuous function and by passing gradients between the image space and the prompt embedding space, we propose and analyze a new method to directly manipulate the embedding of a prompt instead of the prompt text. We then derive three practical interaction tools to support users with image generation: (1) Optimization of a metric defined in the image space that measures, for example, the image style. (2) Supporting a user in creative tasks by allowing them to navigate in the image space along a selection of directions of ""near"" prompt embeddings. (3) Changing the embedding of the prompt to include information that a user has seen in a particular seed but has difficulty describing in the prompt. Compared to prompt engineering, user-driven prompt embedding manipulation enables a more fine-grained, targeted control that integrates a user's intentions. Our user study shows that our methods are considered less tedious and that the resulting images are often preferred."
"Measuring interaction forces in surgical telemanipulation using conventional instruments.","2023","Robotica","Max B. Schäfer, Anja M. Glöckner, Gerrit R. Friedrich, Johannes G. Meiringer, Peter P. Pott","Journal Articles","https://dblp.org/rec/journals/robotica/SchaferGFMP23","Abstract Minimally invasive surgery (MIS) has been an essential tool in the surgical sector for many years due to its crucial advantages compared to open surgery. To overcome remaining limitations, teleoperated MIS experienced a strong emergence. However, the widespread usage of such systems is hindered by the enormous financial hurdle. The use of standard components and conventional tools for teleoperated MIS can facilitate integration into existing hospital workflows and can be a cost-efficient and versatile approach for research purposes. To compensate for the lack of haptic feedback, some teleoperation setups inherit a sensor system allowing them to record interaction forces and display them at the user interface. In research and in commercially available systems, different positions for the sensor can be found. In this paper, mechanical interfaces for the guidance and actuation of non-wristed and wristed standard instruments are presented. Furthermore, a method for the extracorporeal measurement of interaction forces is presented, characterized, and discussed. The overall mean relative error of the magnitude of the interaction force is 9.4%, while the overall mean absolute error of the force vector is 14.4 
$^{\circ }$
 , both below the respective human differential perception threshold. The presented measurement method is a simple, yet sufficiently accurate approach to measure interaction forces in surgical telemanipulation."
"Novel and inexpensive gamma radiation sensor: initial concept and design.","2023","Int. J. Comput. Assist. Radiol. Surg.","Joanna Sorysz, Katarzyna Heryan, Gabriele Krombach, Michael Friebe, Peter P. Pott","Journal Articles","https://dblp.org/rec/journals/cars/SoryszHKFP23","Abstract
                Purpose
                Early detection of tumors and their spread, particularly in lymph node illnesses, is critical for a full recovery. However, it is currently difficult due to a lack of imaging or detection devices that provide the necessary spatial depth and location information. Consequently, it would be beneficial to have a simple and cost-effective sensor device to determine the 3D position of, e.g., a lymph node in the patient’s coordinate system.
              
                Methods
                In this work, we present a concept and design for a novel semiconductor-based 3D detection system that uses inexpensive off-the-shelf components to measure gamma activity. A simple Arduino-type microcontroller calculates the 3D position of the probe based on the number of the measured pulse, the spatial sensitivity characteristics, and the known geometry of the device.
              
                Results
                The system was set up from four photodiodes (Osram BPW34), a transistor-based pre-amplifier, and a two-stage operational amplifier as the main stage. Doing so, a signal sufficient to be read by the microcontroller could be produced. The performed calculations proved that for a system consisting of at least four photodiodes, it is possible to determine precise location of a gamma radiation source.
              
                Conclusions
                After successful first experiments with a single diode, the optimal spatial arrangement of the diodes as well as their orientation will be determined to achieve a compact, cost effective yet fast, and accurate sensor device for every-day clinical application."
"SynpleTest: Using Program Synthesis as a Teaching Aid.","2023","SIGCSE","Alexa Hennen, Cameron Hahnfeldt, Grace Potter, Mengzhen Li, Peter Ohmann","Conference and Workshop Papers","https://dblp.org/rec/conf/sigcse/HennenHPLO23","This poster presents SynpleTest, a teaching tool created for introductory computer science courses. SynpleTest uses program synthesis to generate code based on test cases given by the user. Students must continue to add test cases until SynpleTest generates the program they desire. By doing this, our program teaches the student the importance of producing thoughtful and diverse test cases to improve fundamental understanding of testing programs. Preliminary experimentation in classrooms is underway and initial results of usability and effectiveness are being analyzed."
