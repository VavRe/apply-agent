"title","year","venue","authors","type","url","abstract"
"15.4 Self-Enabled Write-Assist Cells for High-Density SRAM in a Resistance-Dominated Technology Node.","2024","ISSCC","Minjune Yeo, Keonhee Cho, Giseok Kim, Won Joon Jo, Jisang Oh, Sekeon Kim, Kyeongrim Baek, Sungho Park, Seung Jae Yei, Seong-Ook Jung","Conference and Workshop Papers","https://dblp.org/rec/conf/isscc/YeoCKJOKBPYJ24","For applications where a significant amount of data is processed within a limited area, such as mobile and graphics applications, the demand for higher-density SRAM becomes more evident [1]. As shown in Fig. 15.4.1 (top left), SRAM cell area is progressively decreasing with technology scaling to achieve high-density [2]. However, in sub-5nm technology nodes, shown in Fig. 15.4.1 (top right), the reduction of the interconnect cross-sectional area and decreased electron mobility, due to grain boundary scattering and surface scattering, leads to an exponential increase in interconnect resistance. Despite scaling-driven BL length reduction an exponential increase in interconnect resistance results in an increase in the BL resistance per cell $(\mathrm{R}_{\mathrm{BL} \_ \text {cell }})$, resulting in writability degradation. Figure 15.4.1 (bottom) shows the $\mathrm{R}_{\mathrm{BL} \_ \text {cell }}$ and BL capacitance per cell $(\mathrm{C}_{\mathrm{BL} \_ \text {cell }})$ for recent work using sub-5nm technology nodes. As shown in Fig. 15.4.2, the voltage of BL (or BLB) connected to the selected cell $(\mathrm{V}_{\mathrm{BL} \_ \text {cell }})$ is determined by the voltage dividing characteristic from the cell supply voltage $(\mathrm{V}_{DD_{-}C})$, in the selected cell, to the ground voltage (VSS), in write driver (WD), during a write operation. As RBL becomes larger, so does $\mathrm{V}_{\mathrm{BL} \_ \text {cell }}$. An increased $\mathrm{V}_{\mathrm{BL} \_ \text {cell }}$ reduces the write current through the pass-gate transistor (PG), resulting in write failures."
"A 3.5 to 4.7-GHz Fractional-N ADPLL With a Low-Power Time-Interleaved GRO-TDC of 6.2-ps Resolution in 65-nm CMOS Process.","2024","IEEE Access","Kyoung-Ub Cho, Joonho Gil, Chulhyun Park, Kyu-Jin Cho, Jaewoo Shin, Eun Seong Kim, Yun Seong Eo, Ramesh Harjani, Nam-Young Kim, Taehyoun Oh","Journal Articles","https://dblp.org/rec/journals/access/ChoGPCSKEHKO24","This paper proposes a low-power design method and a low-noise phase offset calibration technique for a gated ring-oscillator time-to-digital converter (GRO-TDC), which normally consumes a large percentage of most all-digital phase-locked loop (ADPLL) power. A single coarse counter logic structure along with time-interleaved even/odd paths significantly reduces the complexity and speed of the TDC logic. The proposed TDC consumes only 0.44 to 24 mW for 0.077 to 24.42 ns of detection range. The multi-path GRO accelerates the oscillation speed and achieves approximately 6.2 ps of time resolution. The GRO-TDC shows –1.43 to 1.35 least-significant bits (LSB) of differential non-linearity (DNL) and –1.32 to 1.96 LSB of integral non-linearity (INL) over a 11-bit dynamic range (DR). The entire ADPLL including the proposed TDC has been fabricated in a 65 nm CMOS process and occupies 0.67 mm2 of active area. The prototype ADPLL consumes 12.22 mW from 1.2 V supply and the TDC consumes only 0.65 mW for a 50-phase offset code. A modified integrating structure in the subsequent digital loop filter (DLF) has been developed to mitigate dithering noise on $V_{ctrl}$ code and the measured reference spur is –69.38 dBc at 3.6 GHz center frequency. The tuning range of the implemented ADPLL is 3.5 to 4.7 GHz by using 2-bit band switching and 5-bit coarse control, while maintaining low- $K_{DCO}$ values to suppress in-band quantization noise. The measured root-mean-square (RMS) jitter is 0.94 ps and 0.99 ps at 3.6 GHz integer-mode and 3.60743 GHz fractional-mode respectively."
"Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks.","2024","CoRR","Bálint Mucsányi, Michael Kirchhof, Seong Joon Oh","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2402-19460",""
"Calibrating Large Language Models Using Their Generations Only.","2024","ACL","Dennis Ulmer, Martin Gubri, Hwaran Lee, Sangdoo Yun, Seong Joon Oh","Conference and Workshop Papers","https://dblp.org/rec/conf/acl/UlmerGLYO24","As large language models (LLMs) are increasingly deployed in user-facing applications, building trust and maintaining safety by accurately quantifying a model's confidence in its prediction becomes even more important. However, finding effective ways to calibrate LLMs - especially when the only interface to the models is their generated text - remains a challenge. We propose APRICOT (auxiliary prediction of confidence targets): A method to set confidence targets and train an additional model that predicts an LLM's confidence based on its textual input and output alone. This approach has several advantages: It is conceptually simple, does not require access to the target model beyond its output, does not interfere with the language generation, and has a multitude of potential usages, for instance by verbalizing the predicted confidence or adjusting the given answer based on the confidence. We show how our approach performs competitively in terms of calibration error for white-box and black-box LLMs on closed-book question-answering to detect incorrect LLM answers."
"HyperCLOVA X Technical Report.","2024","CoRR","Kang Min Yoo, Jaegeun Han, Sookyo In, Heewon Jeon, Jisu Jeong, Jaewook Kang, Hyunwook Kim, Kyung-Min Kim, Munhyong Kim, Sungju Kim, Donghyun Kwak, Hanock Kwak, Se Jung Kwon, Bado Lee, Dongsoo Lee, Gichang Lee, Jooho Lee, Baeseong Park, Seongjin Shin, Joonsang Yu, Seolki Baek, Sumin Byeon, Eungsup Cho, Dooseok Choe, Jeeseung Han, Youngkyun Jin, Hyein Jun, Jaeseung Jung, Chanwoong Kim, Jinhong Kim, Jinuk Kim, Dokyeong Lee, Dong Wook Park, Jeong Min Sohn, Sujung Han, Jiae Heo, Sungju Hong, Mina Jeon, Hyunhoon Jung, Jungeun Jung, Wangkyo Jung, Chungjoon Kim, Hyeri Kim, Jonghyun Kim, Min Young Kim, Soeun Lee, Joonhee Park, Jieun Shin, Sojin Yang, Jungsoon Yoon, Hwaran Lee, Sanghwan Bae, Jeehwan Cha, Karl Gylleus, Donghoon Ham, Mihak Hong, Youngki Hong, Yunki Hong, Dahyun Jang, Hyojun Jeon, Yujin Jeon, Yeji Jeong, Myunggeun Ji, Yeguk Jin, Chansong Jo, Shinyoung Joo, Seunghwan Jung, Adrian Jungmyung Kim, Byoung Hoon Kim, Hyomin Kim, Jungwhan Kim, Minkyoung Kim, Minseung Kim, Sungdong Kim, Yonghee Kim, Youngjun Kim, Youngkwan Kim, Donghyeon Ko, Dughyun Lee, Hayoung Lee, Jaehong Lee, Jieun Lee, Jonghyun Lee, Jongjin Lee, Min Young Lee, Yehbin Lee, Taehong Min, Yuri Min, Kiyoon Moon, Hyangnam Oh, Jaesun Park, Kyuyon Park, Younghun Park, Hanbae Seo, Seunghyun Seo, Mihyun Sim, Gyubin Son, Matt Yeo, Kyung Hoon Yeom, Wonjoon Yoo","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2404-01954","We introduce HyperCLOVA X, a family of large language models (LLMs) tailored to the Korean language and culture, along with competitive capabilities in English, math, and coding. HyperCLOVA X was trained on a balanced mix of Korean, English, and code data, followed by instruction-tuning with high-quality human-annotated datasets while abiding by strict safety guidelines reflecting our commitment to responsible AI. The model is evaluated across various benchmarks, including comprehensive reasoning, knowledge, commonsense, factuality, coding, math, chatting, instruction-following, and harmlessness, in both Korean and English. HyperCLOVA X exhibits strong reasoning capabilities in Korean backed by a deep understanding of the language and cultural nuances. Further analysis of the inherent bilingual nature and its extension to multilingualism highlights the model's cross-lingual proficiency and strong generalization ability to untargeted languages, including machine translation between several language pairs and cross-lingual inference tasks. We believe that HyperCLOVA X can provide helpful guidance for regions or countries in developing their sovereign LLMs."
"INSTRUCTIR: A Benchmark for Instruction Following of Information Retrieval Models.","2024","CoRR","Hanseok Oh, Hyunji Lee, Seonghyeon Ye, Haebin Shin, Hansol Jang, Changwook Jun, Minjoon Seo","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2402-14334",""
"LR-FHSS Transceiver for Direct-to-Satellite IoT Communications: Design, Implementation, and Verification.","2024","CoRR","Sooyeob Jung, Seongah Jeong, Jinkyu Kang, Gyeongrae Im, Sangjae Lee, Mi-Kyung Oh, Joon-Gyu Ryu, Joonhyuk Kang","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2403-14154",""
"Pretrained Visual Uncertainties.","2024","CoRR","Michael Kirchhof, Mark Collier, Seong Joon Oh, Enkelejda Kasneci","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2402-16569","Accurate uncertainty estimation is vital to trustworthy machine learning, yet uncertainties typically have to be learned for each task anew. This work introduces the first pretrained uncertainty modules for vision models. Similar to standard pretraining this enables the zero-shot transfer of uncertainties learned on a large pretraining dataset to specialized downstream datasets. We enable our large-scale pretraining on ImageNet-21k by solving a gradient conflict in previous uncertainty modules and accelerating the training by up to 180x. We find that the pretrained uncertainties generalize to unseen datasets. In scrutinizing the learned uncertainties, we find that they capture aleatoric uncertainty, disentangled from epistemic components. We demonstrate that this enables safe retrieval and uncertainty-aware dataset visualization. To encourage applications to further problems and domains, we release all pretrained checkpoints and code under https://github.com/mkirchhof/url ."
"SNNSim: Investigation and Optimization of Large-Scale Analog Spiking Neural Networks Based on Flash Memory Devices.","2024","Adv. Intell. Syst.","JongHyun Ko, Dongseok Kwon, Joon Hwang, Kyu-Ho Lee, Seongbin Oh, Jeonghyun Kim, Jiseong Im, Ryun-Han Koo, Jae-Joon Kim, Jong-Ho Lee 0002","Journal Articles","https://dblp.org/rec/journals/aisy/KoKHLOKIKKL24","Spiking neural networks (SNNs) have emerged as a novel approach for reducing computational costs by mimicking the biologically plausible operations of neurons and synapses. In this article, large‐scale analog SNNs are investigated and optimized at the hardware‐level by using SNNSim, the novel simulator for SNNs that employ analog synaptic devices and integrate‐and‐fire (I&F) neuron circuits. SNNSim is a reconfigurable simulator that accurately and very quickly models the behavior of the user‐defined device characteristics and returns key metrics such as area, accuracy, latency, and power consumption as output. Notably, SNNSim exhibits exceptional efficiency, as it can process the entire 10 000 Modified National Institute of Standards and Technology (MNIST) test dataset in a few seconds, whereas SPICE simulations require hours to simulate a single MNIST test data. Using SNNSim, the conversion of artificial neural networks (ANNs) to SNNs is simulated and the performance of the large‐scale analog SNNs is optimized. The results enable the design of accurate, high‐speed, and low‐power operation of large‐scale SNNs. SNNSim code is now available at https://github.com/SMDLGITHUB/SNNSim."
"TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification.","2024","ACL","Martin Gubri, Dennis Ulmer, Hwaran Lee, Sangdoo Yun, Seong Joon Oh","Conference and Workshop Papers","https://dblp.org/rec/conf/acl/GubriULYO24","Large Language Model (LLM) services and models often come with legal rules on who can use them and how they must use them. Assessing the compliance of the released LLMs is crucial, as these rules protect the interests of the LLM contributor and prevent misuse. In this context, we describe the novel fingerprinting problem of Black-box Identity Verification (BBIV). The goal is to determine whether a third-party application uses a certain LLM through its chat function. We propose a method called Targeted Random Adversarial Prompt (TRAP) that identifies the specific LLM in use. We repurpose adversarial suffixes, originally proposed for jailbreaking, to get a pre-defined answer from the target LLM, while other models give random answers. TRAP detects the target LLMs with over 95% true positive rate at under 0.2% false positive rate even after a single interaction. TRAP remains effective even if the LLM has minor changes that do not significantly alter the original function."
"The BiGGen Bench: A Principled Benchmark for Fine-grained Evaluation of Language Models with Language Models.","2024","CoRR","Seungone Kim, Juyoung Suk, Ji Yong Cho, Shayne Longpre, Chaeeun Kim, Dongkeun Yoon, Guijin Son, Yejin Choi 0001, Sheikh Shafayat, Jinheon Baek, Sue Hyun Park, Hyeonbin Hwang, Jinkyung Jo, Hyowon Cho, Haebin Shin, Seongyun Lee, Hanseok Oh, Noah Lee, Namgyu Ho, Se June Joo, Miyoung Ko, Yoonjoo Lee, Hyungjoo Chae, Jamin Shin, Joel Jang, Seonghyeon Ye, Bill Yuchen Lin, Sean Welleck, Graham Neubig, Moontae Lee, Kyungjae Lee 0002, Minjoon Seo","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2406-05761","As language models (LMs) become capable of handling a wide range of tasks, their evaluation is becoming as challenging as their development. Most generation benchmarks currently assess LMs using abstract evaluation criteria like helpfulness and harmlessness, which often lack the flexibility and granularity of human assessment. Additionally, these benchmarks tend to focus disproportionately on specific capabilities such as instruction following, leading to coverage bias. To overcome these limitations, we introduce the BiGGen Bench, a principled generation benchmark designed to thoroughly evaluate nine distinct capabilities of LMs across 77 diverse tasks. A key feature of the BiGGen Bench is its use of instance-specific evaluation criteria, closely mirroring the nuanced discernment of human evaluation. We apply this benchmark to assess 103 frontier LMs using five evaluator LMs. Our code, data, and evaluation results are all publicly available at https://github.com/prometheus-eval/prometheus-eval/tree/main/BiGGen-Bench."
"A 1.1V 16Gb DDR5 DRAM with Probabilistic-Aggressor Tracking, Refresh-Management Functionality, Per-Row Hammer Tracking, a Multi-Step Precharge, and Core-Bias Modulation for Security and Reliability Enhancement.","2023","ISSCC","Woongrae Kim, Chulmoon Jung, Seong Nyuh Yoo, Duckhwa Hong, Jeongjin Hwang, Jungmin Yoon, Oh-Yong Jung, Joonwoo Choi, Sanga Hyun, Mankeun Kang, Sangho Lee, Dohong Kim, Sanghyun Ku, Donhyun Choi, Nogeun Joo, Sangwoo Yoon, Junseok Noh, Byeongyong Go, Cheolhoe Kim, Sunil Hwang, Mihyun Hwang, Seol-Min Yi, Hyungmin Kim, Sanghyuk Heo, Yeonsu Jang, Kyoungchul Jang, Shinho Chu, Yoonna Oh, Kwidong Kim, Junghyun Kim, Soohwan Kim, Jeongtae Hwang, Sangil Park, Junphyo Lee, In-Chul Jeong, Joohwan Cho, Jonghwan Kim","Conference and Workshop Papers","https://dblp.org/rec/conf/isscc/KimJYHHYJCHKLKKCJYNGKHHYKHJJCOKKKHPLJ23","DRAM products have been recently adopted in a wide range of high-performance computing applications: such as in cloud computing, in big data systems, and loT devices. This demand creates larger memory capacity requirements, thereby requiring aggressive DRAM technology node scaling to reduce the cost per bit [1], [2]. However, DRAM manufacturers are facing technology scaling challenges due to row hammer and refresh retention time beyond 1a-nm [2]. Row hammer is a failure mechanism, where repeatedly activating a DRAM row disturbs data in adjacent rows. Scaling down severely threatens reliability since a reduction of DRAM cell size leads to a reduction in the intrinsic row hammer tolerance [2], [3]. To improve row hammer tolerance, there is a need to probabilistically activate adjacent rows with carefully sampled active addresses and to improve intrinsic row hammer tolerance [2]. In this paper, row-hammer-protection and refresh-management schemes are presented to guarantee DRAM security and reliability despite the aggressive scaling from 1a-nm to sub 10-nm nodes. The probabilistic-aggressor-tracking scheme with a refresh-management function (RFM) and per-tow hammer tracking (PRHT) improve DRAM resilience. A multi-step precharge reinforces intrinsic row-hammer tolerance and a core-bias modulation improves retention time: even in the face of cell-transistor degradation due to technology scaling. This comprehensive scheme leads to a reduced probability of failure, due to row hammer attacks, by 93.1% and an improvement in retention time by 17%."
"A Bayesian Approach To Analysing Training Data Attribution In Deep Learning.","2023","NeurIPS","Elisa Nguyen, Minjoon Seo, Seong Joon Oh","Conference and Workshop Papers","https://dblp.org/rec/conf/nips/NguyenSO23","Training data attribution (TDA) techniques find influential training data for the model's prediction on the test data of interest. They approximate the impact of down- or up-weighting a particular training sample. While conceptually useful, they are hardly applicable to deep models in practice, particularly because of their sensitivity to different model initialisation. In this paper, we introduce a Bayesian perspective on the TDA task, where the learned model is treated as a Bayesian posterior and the TDA estimates as random variables. From this novel viewpoint, we observe that the influence of an individual training sample is often overshadowed by the noise stemming from model initialisation and SGD batch composition. Based on this observation, we argue that TDA can only be reliably used for explaining deep model predictions that are consistently influenced by certain training data, independent of other noise factors. Our experiments demonstrate the rarity of such noise-independent training-test data pairs but confirm their existence. We recommend that future researchers and practitioners trust TDA estimates only in such cases. Further, we find a disagreement between ground truth and estimated TDA distributions and encourage future work to study this gap. Code is provided at https://github.com/ElisaNguyen/bayesian-tda."
"A Bayesian Perspective On Training Data Attribution.","2023","CoRR","Elisa Nguyen, Minjoon Seo, Seong Joon Oh","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2305-19765","Training data attribution (TDA) techniques find influential training data for the model's prediction on the test data of interest. They approximate the impact of down- or up-weighting a particular training sample. While conceptually useful, they are hardly applicable to deep models in practice, particularly because of their sensitivity to different model initialisation. In this paper, we introduce a Bayesian perspective on the TDA task, where the learned model is treated as a Bayesian posterior and the TDA estimates as random variables. From this novel viewpoint, we observe that the influence of an individual training sample is often overshadowed by the noise stemming from model initialisation and SGD batch composition. Based on this observation, we argue that TDA can only be reliably used for explaining deep model predictions that are consistently influenced by certain training data, independent of other noise factors. Our experiments demonstrate the rarity of such noise-independent training-test data pairs but confirm their existence. We recommend that future researchers and practitioners trust TDA estimates only in such cases. Further, we find a disagreement between ground truth and estimated TDA distributions and encourage future work to study this gap. Code is provided at https://github.com/ElisaNguyen/bayesian-tda."
"An Arrhythmia Classification-Guided Segmentation Model for Electrocardiogram Delineation.","2023","CoRR","Chankyu Joung, Mijin Kim, Taejin Paik, Seong-Ho Kong, Seung-Young Oh, Won Kyeong Jeon, Jae-hu Jeon, Joong-Sik Hong, Wan-Joong Kim, Woong Kook, Myung-Jin Cha, Otto van Koert","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2304-06237",". Accurate delineation of key waveforms in an ECG is a critical initial step in extracting relevant features to support the diagnosis and treatment of heart conditions. Although deep learning based methods using a segmentation model to locate P, QRS and T waves have shown promising results, their ability to handle signals exhibiting arrhythmia remains unclear. In this study, we propose a novel approach that leverages a deep learning model to accurately delineate signals with a wide range of arrhythmia. Our approach involves training a segmentation model using a hybrid loss function that combines segmentation with the task of arrhythmia classiﬁcation. In addition, we use a diverse training set containing various arrhythmia types, enabling our model to handle a wide range of challenging cases. Experimental results show that our model accurately delineates signals with a broad range of abnormal rhythm types, and the combined training with classiﬁcation guidance can eﬀec-tively reduce false positive P wave predictions, particularly during atrial ﬁbrillation and atrial ﬂutter. Furthermore, our proposed method shows competitive performance with previous delineation algorithms on the Lobachevsky University Database (LUDB)."
"ECG-QA: A Comprehensive Question Answering Dataset Combined With Electrocardiogram.","2023","NeurIPS","Jungwoo Oh, Gyubok Lee, Seongsu Bae, Joon-Myoung Kwon, Edward Choi","Conference and Workshop Papers","https://dblp.org/rec/conf/nips/OhLBKC23",""
"Enhancing Discriminative Ability among Similar Classes with Guidance of Text-Image Correlation for Unsupervised Domain Adaptation.","2023","IJCNN","Yu-Won Lee, Myeong-Seok Oh, Ho-Joong Kim, Seong-Whan Lee","Conference and Workshop Papers","https://dblp.org/rec/conf/ijcnn/LeeOKL23","In deep learning, unsupervised domain adaptation (UDA) is commonly utilized when the availability of abundant labeled data is often limited. Several methods have been proposed for UDA to overcome the difficulty of distinguishing between semantically similar classes, such as person vs. rider and road vs. sidewalk. The confusion of the classes results from the collapse of the distance, caused by the domain shift, between classes in the feature space. In this work, we present a versatile approach based on text-image correlation-guided domain adaptation (TigDA), which maintains a distance to properly adjust the decision boundaries between classes in the feature space. In our approach, the feature information is extracted through text embedding of classes and the aligning capability of the text features with the image features is achieved using the cross-modality. The resultant cross-modal features play an essential role in generating pseudo-labels and calculating an auxiliary pixel-wise cross-entropy loss to assist the image encoder in learning the distribution of cross-modal features. Such a guiding process allows the extension of the distance between similar classes in feature space so that a proper distance for adjusting the decision boundary is maintained. Our TigDA achieved the highest performance among other UDA methods in both single-resolution and multi-resolution cases with the help of GTA5 and SYNTHIA for the source domain and Cityscapes for the target domain. The simplicity and versatility of TigDA will be widely applicable for enhancing the self-training capabilities of most UDA methods."
"Neglected Free Lunch - Learning Image Classifiers Using Annotation Byproducts.","2023","ICCV","Dongyoon Han, Junsuk Choe, Seonghyeok Chun, John Joon Young Chung, Minsuk Chang, Sangdoo Yun, Jean Y. Song, Seong Joon Oh","Conference and Workshop Papers","https://dblp.org/rec/conf/iccv/HanCCCCYSO23","Supervised learning of image classifiers distills human knowledge into a parametric model fθ through pairs of images and corresponding labels $\left\{ {\left( {{X_i},{Y_i}} \right)} \right\}_{i = 1}^N$. We argue that this simple and widely used representation of human knowledge neglects rich auxiliary information from the annotation procedure, such as the time-series of mouse traces and clicks left after image selection. Our insight is that such annotation byproducts Z provide approximate human attention that weakly guides the model to focus on the foreground cues, reducing spurious correlations and discouraging shortcut learning. To verify this, we create ImageNet-AB and COCO-AB. They are ImageNet and COCO training sets enriched with sample-wise annotation byproducts, collected by replicating the respective original annotation tasks. We refer to the new paradigm of training models with annotation byproducts as learning using annotation byproducts (LUAB). We show that a simple multitask loss for regressing Z together with Y already improves the generalisability and robustness of the learned models. Compared to the original supervised learning, LUAB does not require extra annotation costs. ImageNet-AB and COCO-AB are at github.com/naverai/NeglectedFreeLunch."
"Neglected Free Lunch; Learning Image Classifiers Using Annotation Byproducts.","2023","CoRR","Dongyoon Han, Junsuk Choe, Seonghyeok Chun, John Joon Young Chung, Minsuk Chang, Sangdoo Yun, Jean Y. Song, Seong Joon Oh","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2303-17595","Supervised learning of image classifiers distills human knowledge into a parametric model fθ through pairs of images and corresponding labels $\left\{ {\left( {{X_i},{Y_i}} \right)} \right\}_{i = 1}^N$. We argue that this simple and widely used representation of human knowledge neglects rich auxiliary information from the annotation procedure, such as the time-series of mouse traces and clicks left after image selection. Our insight is that such annotation byproducts Z provide approximate human attention that weakly guides the model to focus on the foreground cues, reducing spurious correlations and discouraging shortcut learning. To verify this, we create ImageNet-AB and COCO-AB. They are ImageNet and COCO training sets enriched with sample-wise annotation byproducts, collected by replicating the respective original annotation tasks. We refer to the new paradigm of training models with annotation byproducts as learning using annotation byproducts (LUAB). We show that a simple multitask loss for regressing Z together with Y already improves the generalisability and robustness of the learned models. Compared to the original supervised learning, LUAB does not require extra annotation costs. ImageNet-AB and COCO-AB are at github.com/naverai/NeglectedFreeLunch."
"Scratching Visual Transformer's Back with Uniform Attention.","2023","ICCV","Nam Hyeon-Woo, Kim Yu-Ji, Byeongho Heo, Dongyoon Han, Seong Joon Oh, Tae-Hyun Oh","Conference and Workshop Papers","https://dblp.org/rec/conf/iccv/Hyeon-WooYHHOO23","The favorable performance of Vision Transformers (ViTs) is often attributed to the multi-head self-attention (MSA), which enables global interactions at each layer of a ViT model. Previous works acknowledge the property of long-range dependency for the effectiveness in MSA. In this work, we study the role of MSA in terms of the different axis, density. Our preliminary analyses suggest that the spatial interactions of learned attention maps are close to dense interactions rather than sparse ones. This is a curious phenomenon because dense attention maps are harder for the model to learn due to softmax. We interpret this opposite behavior against softmax as a strong preference for the ViT models to include dense interaction. We thus manually insert the dense uniform attention to each layer of the ViT models to supply the much-needed dense interactions. We call this method Context Broadcasting, CB. Our study demonstrates the inclusion of CB takes the role of dense attention and thereby reduces the degree of density in the original attention maps by complying softmax in MSA. We also show that, with negligible costs of CB (1 line in your model code and no additional parameters), both the capacity and generalizability of the ViT models are increased."
"Do Deep Neural Network Solutions Form a Star Domain?","2024","CoRR","Ankit Sonthalia, Alexander Rubinstein 0002, Ehsan Abbasnejad, Seong Joon Oh","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2403-07968","It has recently been conjectured that neural network solution sets reachable via stochastic gradient descent (SGD) are convex, considering permutation invariances (Entezari et al., 2022). This means that a linear path can connect two independent solutions with low loss, given the weights of one of the models are appropriately permuted. However, current methods to test this theory often require very wide networks to succeed. In this work, we conjecture that more generally, the SGD solution set is a""star domain""that contains a""star model""that is linearly connected to all the other solutions via paths with low loss values, modulo permutations. We propose the Starlight algorithm that finds a star model of a given learning task. We validate our claim by showing that this star model is linearly connected with other independently found solutions. As an additional benefit of our study, we demonstrate better uncertainty estimates on the Bayesian Model Averaging over the obtained star domain. Further, we demonstrate star models as potential substitutes for model ensembles. Our code is available at https://github.com/aktsonthalia/starlight."
"Scalable Ensemble Diversification for OOD Generalization and Detection.","2024","CoRR","Alexander Rubinstein 0002, Luca Scimeca, Damien Teney, Seong Joon Oh","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2409-16797","Deep neural network (DNN) models are usually built based on the i.i.d. (independent and identically distributed), also known as in-distribution (ID), assumption on the training samples and test data. However, when models are deployed in a real-world scenario with some distributional shifts, test data can be out-of-distribution (OOD) and both OOD detection and OOD generalization should be simultaneously addressed to ensure the reliability and safety of applied AI systems. Most existing OOD detectors pursue these two goals separately, and therefore, are sensitive to covariate shift rather than semantic shift. To alleviate this problem, this paper proposes a novel adversarial mixup (AM) training method which simply executes OOD data augmentation to synthesize differently distributed data and designs a new AM loss function to learn how to handle OOD data. The proposed AM generates OOD samples being significantly diverged from the support of training data distribution but not completely disjoint to increase the generalization capability of the OOD detector. In addition, the AM is combined with a distributional-distance-aware OOD detector at inference to detect semantic OOD samples more efficiently while being robust to covariate shift due to data tampering. Experimental evaluation validates that the designed AM is effective on both OOD detection and OOD generalization tasks compared to previous OOD detectors and data mixup methods."
"Studying Large Language Model Behaviors Under Realistic Knowledge Conflicts.","2024","CoRR","Evgenii Kortukov, Alexander Rubinstein 0002, Elisa Nguyen, Seong Joon Oh","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2404-16032","Retrieval-augmented generation (RAG) mitigates many problems of fully parametric language models, such as temporal degradation, hallucinations, and lack of grounding. In RAG, the model’s knowledge can be updated from documents provided in context. This leads to cases of conflict between the model’s parametric knowledge and the contextual information, where the model may not always update its knowledge. Previous work studied knowledge conflicts by creating synthetic documents that contradict the model’s correct parametric answers. We present a framework for studying knowledge conflicts in a realistic setup. We update incorrect parametric knowledge using real conflicting documents. This reflects how knowledge conflicts arise in practice. In this realistic scenario, we find that knowledge updates fail less often than previously reported. In cases where the models still fail to update their answers, we find a parametric bias: the incorrect parametric answer appearing in context makes the knowledge update likelier to fail. These results suggest that the factual parametric knowledge of LLMs can negatively influence their reading abilities and behaviors. Our code is available at: https://github.com/kortukov/realistic_knowledge_conflicts/ ."
"Towards User-Focused Research in Training Data Attribution for Human-Centered Explainable AI.","2024","CoRR","Elisa Nguyen, Johannes Bertram, Evgenii Kortukov, Jean Y. Song, Seong Joon Oh","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2409-16978","While Explainable AI (XAI) aims to make AI understandable and useful to humans, it has been criticised for relying too much on formalism and solutionism, focusing more on mathematical soundness than user needs. We propose an alternative to this bottom-up approach inspired by design thinking: the XAI research community should adopt a top-down, user-focused perspective to ensure user relevance. We illustrate this with a relatively young subfield of XAI, Training Data Attribution (TDA). With the surge in TDA research and growing competition, the field risks repeating the same patterns of solutionism. We conducted a needfinding study with a diverse group of AI practitioners to identify potential user needs related to TDA. Through interviews (N=10) and a systematic survey (N=31), we uncovered new TDA tasks that are currently largely overlooked. We invite the TDA and XAI communities to consider these novel tasks and improve the user relevance of their research outcomes."
"A 1ynm 1.25V 8Gb 16Gb/s/Pin GDDR6-Based Accelerator-in-Memory Supporting 1TFLOPS MAC Operation and Various Activation Functions for Deep Learning Application.","2023","IEEE J. Solid State Circuits","Dae-Han Kwon, Seongju Lee, Kyuyoung Kim, Sanghoon Oh, Joonhong Park, Gimoon Hong, Dongyoon Ka, Kyu-Dong Hwang, Jeongje Park, Kyeong Pil Kang, Jungyeon Kim, Junyeol Jeon, Nahsung Kim, Yongkee Kwon, Kornijcuk Vladimir, Woojae Shin, Jongsoon Won, Minkyu Lee, Hyunha Joo, Haerang Choi, Guhyun Kim, Byeongju An, Jaewook Lee, Donguc Ko, Younggun Jun, Ilwoong Kim, Choungki Song, Ilkon Kim, Chanwook Park, Seho Kim, Chunseok Jeong, Euicheol Lim, Dongkyun Kim, Jieun Jang, Il Park 0001, Junhyun Chun, Joohwan Cho","Journal Articles","https://dblp.org/rec/journals/jssc/KwonLKOPHKHPKKJ23","In this article, a 1.25-V 8-Gb, 16-Gb/s/pin GDDR6-based accelerator-in-memory (AiM) is presented. A dedicated command (CMD) set for deep learning (DL) is introduced to minimize latency when switching operation modes, and a bank-wide mantissa shift (BWMS) scheme is adopted to minimize calculation delay time, current consumption, and circuit area during multiply-accumulate (MAC) operation. By storing the lookup table (LUT) in the reserved word line in the dynamic random access memory (DRAM) bank cell, it is possible to support various activation functions (AFs), such as Gaussian error linear unit (GELU), sigmoid, and Tanh as well as rectified linear unit (ReLU) and Leaky ReLU. Performance evaluation was conducted by measuring the fabricated chip in ATE and a self-manufactured field-programmable gate array (FPGA)-based system. In the ATE-level evaluation, it operates at 16 Gbps up to a voltage as low as 1.10 V. When evaluated by GEMV and MNIST in the FPGA-based system, it was confirmed that the performance gains of 7.5–10.5 times were possible compared to the HBM2-based or GDDR6-based systems."
"All-Flash Array Key-Value Cache for Large Objects.","2023","EuroSys","Jinhyung Koo, Jinwook Bae, Minjeong Yuk, Seonggyun Oh, Jungwoo Kim, Jung-Soo Park, Eunji Lee, Bryan S. Kim, Sungjin Lee 0001","Conference and Workshop Papers","https://dblp.org/rec/conf/eurosys/KooBYOKPLKL23","We present BigKV, a key-value cache specifically designed for caching large objects in an all-flash array (AFA). The design of BigKV is centered around the unique property of a cache: since it contains a copy of the data, exact bookkeeping of what is in the cache is not critical for correctness. By ignoring hash collisions, approximating metadata information, and allowing data loss from failures, BigKV significantly increases the cache hit ratio and keeps more useful objects in the system. Experiments on a real AFA show that our design increases the throughput by 3.1× on average and reduces the average and tail latency by 57% and 81%, respectively."
"Evaluation for Weakly Supervised Object Localization: Protocol, Metrics, and Datasets.","2023","IEEE Trans. Pattern Anal. Mach. Intell.","Junsuk Choe, Seong Joon Oh, Sanghyuk Chun, Seungho Lee, Zeynep Akata, Hyunjung Shim","Journal Articles","https://dblp.org/rec/journals/pami/ChoeOCLAS23","Weakly-supervised object localization (WSOL) has gained popularity over the last years for its promise to train localization models with only image-level labels. Since the seminal WSOL work of class activation mapping (CAM), the field has focused on how to expand the attention regions to cover objects more broadly and localize them better. However, these strategies rely on full localization supervision for validating hyperparameters and model selection, which is in principle prohibited under the WSOL setup. In this paper, we argue that WSOL task is ill-posed with only image-level labels, and propose a new evaluation protocol where full supervision is limited to only a small held-out set not overlapping with the test set. We observe that, under our protocol, the five most recent WSOL methods have not made a major improvement over the CAM baseline. Moreover, we report that existing WSOL methods have not reached the few-shot learning baseline, where the full-supervision at validation time is used for model training instead. Based on our findings, we discuss some future directions for WSOL. Source code and dataset are available at https://github.com/clovaai/wsolevaluation https://github.com/clovaai/wsolevaluation."
"Exploring Practitioner Perspectives On Training Data Attribution Explanations.","2023","CoRR","Elisa Nguyen, Evgenii Kortukov, Jean Y. Song, Seong Joon Oh","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2310-20477","Explainable AI (XAI) aims to provide insight into opaque model reasoning to humans and as such is an interdisciplinary field by nature. In this paper, we interviewed 10 practitioners to understand the possible usability of training data attribution (TDA) explanations and to explore the design space of such an approach. We confirmed that training data quality is often the most important factor for high model performance in practice and model developers mainly rely on their own experience to curate data. End-users expect explanations to enhance their interaction with the model and do not necessarily prioritise but are open to training data as a means of explanation. Within our participants, we found that TDA explanations are not well-known and therefore not used. We urge the community to focus on the utility of TDA techniques from the human-machine collaboration perspective and broaden the TDA evaluation to reflect common use cases in practice."
"ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets.","2023","NeurIPS","Damien Teney, Yong Lin, Seong Joon Oh, Ehsan Abbasnejad","Conference and Workshop Papers","https://dblp.org/rec/conf/nips/TeneyLOA23",""
"Investigation of Sub-20nm 4th generation DRAM cell transistor's parasitic resistance and scalable methodology for Sub-20nm era.","2023","IRPS","Shinwoo Jeong, Jin-Seong Lee, Jiuk Jang, Jooncheol Kim, Hyunsu Shin, Jihun Kim, Jeongwoo Song, Dongsoo Woo, Jeonghoon Oh, Jooyoung Lee","Conference and Workshop Papers","https://dblp.org/rec/conf/irps/JeongLJKSKSWOL23","The component of cell parasitic resistance at sub-20nm 4th generation DRAM cell transistor is investigated. To evaluate the cell characteristics, the Gate Buried Contact (GBC) to Active contact formation method with varied dopant concentrations was studied. We have discovered a scalable methodology that simultaneously reduces parasitic resistance and leakage with regard to Gate Induced Drain Leakage (GIDL). Also, we proved the importance of interface quality of Direct Contact on Cell (DCC) in order to reduce the parasitic resistance. The failure analysis is conducted by segmenting the resistance with Test Element Groups (TEGs) at wafer level. And the process windows and local variations from fabricated devices are electrically verified by core failure analysis. Through this investigation, we proposed the scalable methodology that can sustain generational scalability of DRAM."
"Playing repeated games with Large Language Models.","2023","CoRR","Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, Eric Schulz","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2305-16867","Large Language Models (LLMs) are transforming society and permeating into diverse applications. As a result, LLMs will frequently interact with us and other agents. It is, therefore, of great societal value to understand how LLMs behave in interactive social settings. Here, we propose to use behavioral game theory to study LLM's cooperation and coordination behavior. To do so, we let different LLMs (GPT-3, GPT-3.5, and GPT-4) play finitely repeated games with each other and with other, human-like strategies. Our results show that LLMs generally perform well in such tasks and also uncover persistent behavioral signatures. In a large set of two players-two strategies games, we find that LLMs are particularly good at games where valuing their own self-interest pays off, like the iterated Prisoner's Dilemma family. However, they behave sub-optimally in games that require coordination. We, therefore, further focus on two games from these distinct families. In the canonical iterated Prisoner's Dilemma, we find that GPT-4 acts particularly unforgivingly, always defecting after another agent has defected only once. In the Battle of the Sexes, we find that GPT-4 cannot match the behavior of the simple convention to alternate between options. We verify that these behavioral signatures are stable across robustness checks. Finally, we show how GPT-4's behavior can be modified by providing further information about the other player as well as by asking it to predict the other player's actions before making a choice. These results enrich our understanding of LLM's social behavior and pave the way for a behavioral game theory for machines."
"ProPILE: Probing Privacy Leakage in Large Language Models.","2023","NeurIPS","Siwon Kim, Sangdoo Yun, Hwaran Lee, Martin Gubri, Sungroh Yoon, Seong Joon Oh","Conference and Workshop Papers","https://dblp.org/rec/conf/nips/KimYLGYO23","The rapid advancement and widespread use of large language models (LLMs) have raised significant concerns regarding the potential leakage of personally identifiable information (PII). These models are often trained on vast quantities of web-collected data, which may inadvertently include sensitive personal data. This paper presents ProPILE, a novel probing tool designed to empower data subjects, or the owners of the PII, with awareness of potential PII leakage in LLM-based services. ProPILE lets data subjects formulate prompts based on their own PII to evaluate the level of privacy intrusion in LLMs. We demonstrate its application on the OPT-1.3B model trained on the publicly available Pile dataset. We show how hypothetical data subjects may assess the likelihood of their PII being included in the Pile dataset being revealed. ProPILE can also be leveraged by LLM service providers to effectively evaluate their own levels of PII leakage with more powerful prompts specifically tuned for their in-house models. This tool represents a pioneering step towards empowering the data subjects for their awareness and control over their own data on the web."
"Probabilistic Contrastive Learning Recovers the Correct Aleatoric Uncertainty of Ambiguous Inputs.","2023","ICML","Michael Kirchhof, Enkelejda Kasneci, Seong Joon Oh","Conference and Workshop Papers","https://dblp.org/rec/conf/icml/KirchhofKO23","Contrastively trained encoders have recently been proven to invert the data-generating process: they encode each input, e.g., an image, into the true latent vector that generated the image (Zimmermann et al., 2021). However, real-world observations often have inherent ambiguities. For instance, images may be blurred or only show a 2D view of a 3D object, so multiple latents could have generated them. This makes the true posterior for the latent vector probabilistic with heteroscedastic uncertainty. In this setup, we extend the common InfoNCE objective and encoders to predict latent distributions instead of points. We prove that these distributions recover the correct posteriors of the data-generating process, including its level of aleatoric uncertainty, up to a rotation of the latent space. In addition to providing calibrated uncertainty estimates, these posteriors allow the computation of credible intervals in image retrieval. They comprise images with the same latent as a given query, subject to its uncertainty. Code is available at https://github.com/mkirchhof/Probabilistic_Contrastive_Learning"
"Shortcut Bias Mitigation via Ensemble Diversity Using Diffusion Probabilistic Models.","2023","CoRR","Luca Scimeca, Alexander Rubinstein 0002, Damien Teney, Seong Joon Oh, Armand Mihai Nicolicioiu, Yoshua Bengio","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2311-16176","Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to a phenomenon known as shortcut learning, where a model relies on erroneous, easy-to-learn cues while ignoring reliable ones. In this work, we propose DiffDiv an ensemble diversification framework exploiting Diffusion Probabilistic Models (DPMs) to mitigate this form of bias. We show that at particular training intervals, DPMs can generate images with novel feature combinations, even when trained on samples displaying correlated input features. We leverage this crucial property to generate synthetic counterfactuals to increase model diversity via ensemble disagreement. We show that DPM-guided diversification is sufficient to remove dependence on shortcut cues, without a need for additional supervised signals. We further empirically quantify its efficacy on several diversification objectives, and finally show improved generalization and diversification on par with prior work that relies on auxiliary data collection."
"The StarCraft Multi-Agent Exploration Challenges: Learning Multi-Stage Tasks and Environmental Factors Without Precise Reward Functions.","2023","IEEE Access","Mingyu Kim 0002, Jihwan Oh, Yongsik Lee, Joonkee Kim, Seonghwan Kim 0004, Song Chong, Seyoung Yun","Journal Articles","https://dblp.org/rec/journals/access/KimOLKKCY23","In this paper, we propose a novel benchmark called the StarCraft Multi-Agent Exploration Challenges(SMAC-Exp), where agents learn to perform multi-stage tasks and to use environmental factors without precise reward functions. The previous challenges (SMAC) recognized as a standard benchmark of Multi-Agent Reinforcement Learning are mainly concerned with ensuring that all agents cooperatively eliminate approaching adversaries only through fine manipulation with obvious reward functions. SMAC-Exp, on the other hand, is interested in the exploration capability of MARL algorithms to efficiently learn implicit multi-stage tasks and environmental factors as well as micro-control. This study covers both offensive and defensive scenarios. In the offensive scenarios, agents must learn to first find opponents and then eliminate them. The defensive scenarios require agents to use topographic features. For example, agents need to position themselves behind protective structures to make it harder for enemies to attack. We investigate a total of twelve MARL algorithms under both sequential and parallel episode settings of SMAC-Exp and observe that recent approaches perform well in similar settings to the previous challenge, but we discover that current multi-agent approaches place relatively less emphasis on exploration perspectives. To a limited extent, we observe that an enhanced exploration method has a positive effect on SMAC-Exp, however, there is still a gap that state-of-the-art algorithms cannot resolve the most challenging scenarios of SMAC-Exp. Consequently, we propose a new axis for future research into Multi-Agent Reinforcement Learning studies."
"Trustworthy Machine Learning.","2023","CoRR","Bálint Mucsányi, Michael Kirchhof, Elisa Nguyen, Alexander Rubinstein 0002, Seong Joon Oh","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2310-08215","AbstractWe introduce a flexible program synthesis system whose task is to predict function compositions that transform given inputs to their corresponding given outputs. We process input lists in a sequential manner, allowing the system to generalize to a wide range of input lengths. We separate the operator and the operand in the lambda functions of the used higher order functions to achieve significantly wider numeric parameter ranges compared to the previous works. The evaluations show that this approach is competitive with state-of-the-art systems, while it is much more flexible in terms of the input length, the parameters of the lambda functions, and the integer range of the inputs and outputs. We extend the system to handle tree-structured function compositions by introducing two additional functions (, copy) and the ability to represent unfinished function compositions during the synthesis process. The extended system achieves state-of-the-art results while synthesizing complex function compositions with multiple forks. We believe that flexibility in these aspects is an important step towards solving real-world problems with example-based program synthesis."
"URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates.","2023","NeurIPS","Michael Kirchhof, Bálint Mucsányi, Seong Joon Oh, Enkelejda Kasneci","Conference and Workshop Papers","https://dblp.org/rec/conf/nips/KirchhofMOK23","Representation learning has significantly driven the field to develop pretrained models that can act as a valuable starting point when transferring to new datasets. With the rising demand for reliable machine learning and uncertainty quantification, there is a need for pretrained models that not only provide embeddings but also transferable uncertainty estimates. To guide the development of such models, we propose the Uncertainty-aware Representation Learning (URL) benchmark. Besides the transferability of the representations, it also measures the zero-shot transferability of the uncertainty estimate using a novel metric. We apply URL to evaluate eleven uncertainty quantifiers that are pretrained on ImageNet and transferred to eight downstream datasets. We find that approaches that focus on the uncertainty of the representation itself or estimate the prediction risk directly outperform those that are based on the probabilities of upstream classes. Yet, achieving transferable uncertainty quantification remains an open challenge. Our findings indicate that it is not necessarily in conflict with traditional representation learning goals. Code is provided under https://github.com/mkirchhof/url ."
"Zero-Shot Dense Video Captioning by Jointly Optimizing Text and Moment.","2023","CoRR","Yongrae Jo, Seongyun Lee, Aiden SJ Lee, Hyunji Lee, Hanseok Oh, Minjoon Seo","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2307-02682","Dense video captioning, a task of localizing meaningful moments and generating relevant captions for videos, often requires a large, expensive corpus of annotated video segments paired with text. In an effort to minimize the annotation cost, we propose ZeroTA, a novel method for dense video captioning in a zero-shot manner. Our method does not require any videos or annotations for training; instead, it localizes and describes events within each input video at test time by optimizing solely on the input. This is accomplished by introducing a soft moment mask that represents a temporal segment in the video and jointly optimizing it with the prefix parameters of a language model. This joint optimization aligns a frozen language generation model (i.e., GPT-2) with a frozen vision-language contrastive model (i.e., CLIP) by maximizing the matching score between the generated text and a moment within the video. We also introduce a pairwise temporal IoU loss to let a set of soft moment masks capture multiple distinct events within the video. Our method effectively discovers diverse significant events within the video, with the resulting captions appropriately describing these events. The empirical results demonstrate that ZeroTA surpasses zero-shot baselines and even outperforms the state-of-the-art few-shot method on the widely-used benchmark ActivityNet Captions. Moreover, our method shows greater robustness compared to supervised methods when evaluated in out-of-domain scenarios. This research provides insight into the potential of aligning widely-used models, such as language generation models and vision-language models, to unlock a new capability: understanding temporal aspects of videos."
