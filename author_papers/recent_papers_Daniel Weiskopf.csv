"title","year","venue","authors","type","url","abstract"
"Comparative Evaluation of Animated Scatter Plot Transitions - Supplemental Material.","2024","DaRUS","Nils Rodrigues, Frederik L. Dennig, Vincent Brandt, Daniel A. Keim, Daniel Weiskopf","Data and Artifacts","https://dblp.org/rec/data/10/RodriguesDBKW24","Scatter plots are popular for displaying 2D data, but in practice, many data sets have more than two dimensions. For the analysis of such multivariate data, it is often necessary to switch between scatter plots of different dimension pairs, e.g., in a scatter plot matrix (SPLOM). Alternative approaches include a “grand tour” for an overview of the entire data set or creating artificial axes from dimensionality reduction (DR). A cross-cutting concern in all techniques is the ability of viewers to find correspondence between data points in different views. Previous work proposed animations to preserve the mental map between view changes and to trace points as well as clusters between scatter plots of the same underlying data set. In this article, we evaluate a variety of spline- and rotation-based view transitions in a crowdsourced user study focusing on ecological validity. Using the study results, we assess each animation’s suitability for tracing points and clusters across view changes. We evaluate whether the order of horizontal and vertical rotation is relevant for task accuracy. The results show that rotations with an orthographic camera or staged expansion of a depth axis significantly outperform all other animation techniques for the traceability of individual points. Further, we provide a ranking of the animated transition techniques for traceability of individual points. However, we could not find any significant differences for the traceability of clusters. Furthermore, we identified differences by animation direction that could guide further studies to determine potential confounds for these differences. We publish the study data for reuse and provide the animation framework as a D3.js plug-in."
"Comparative Evaluation of Animated Scatter Plot Transitions.","2024","IEEE Trans. Vis. Comput. Graph.","Nils Rodrigues, Frederik L. Dennig, Vincent Brandt, Daniel A. Keim, Daniel Weiskopf","Journal Articles","https://dblp.org/rec/journals/tvcg/RodriguesDBKW24","Scatter plots are popular for displaying 2D data, but in practice, many data sets have more than two dimensions. For the analysis of such multivariate data, it is often necessary to switch between scatter plots of different dimension pairs, e.g., in a scatter plot matrix (SPLOM). Alternative approaches include a “grand tour” for an overview of the entire data set or creating artificial axes from dimensionality reduction (DR). A cross-cutting concern in all techniques is the ability of viewers to find correspondence between data points in different views. Previous work proposed animations to preserve the mental map between view changes and to trace points as well as clusters between scatter plots of the same underlying data set. In this article, we evaluate a variety of spline- and rotation-based view transitions in a crowdsourced user study focusing on ecological validity. Using the study results, we assess each animation’s suitability for tracing points and clusters across view changes. We evaluate whether the order of horizontal and vertical rotation is relevant for task accuracy. The results show that rotations with an orthographic camera or staged expansion of a depth axis significantly outperform all other animation techniques for the traceability of individual points. Further, we provide a ranking of the animated transition techniques for traceability of individual points. However, we could not find any significant differences for the traceability of clusters. Furthermore, we identified differences by animation direction that could guide further studies to determine potential confounds for these differences. We publish the study data for reuse and provide the animation framework as a D3.js plug-in."
"Configuring augmented reality users: analysing YouTube commercials to understand industry expectations.","2024","Behav. Inf. Technol.","Ann-Kathrin Wortmeier, Aimée Sousa Calepso, Cordula Kropp, Michael Sedlmair, Daniel Weiskopf","Journal Articles","https://dblp.org/rec/journals/behaviourIT/WortmeierCKSW24",""
"Exploring visual quality of multidimensional time series projections.","2024","Vis. Informatics","Tanja Munz-Körner, Daniel Weiskopf","Journal Articles","https://dblp.org/rec/journals/vi/MunzKornerW24",""
"Eye Tracking on Text Reading with Visual Enhancements.","2024","ETRA","Franziska Huth, Maurice Koch, Miriam Awad-Mohammed, Daniel Weiskopf, Kuno Kurzhals","Conference and Workshop Papers","https://dblp.org/rec/conf/etra/HuthKAWK24","The interplay between text and visualization is gaining importance for media where traditional text is enriched by visual elements to improve readability and emphasize facts. In two controlled eye-tracking experiments (N = 12), we approach answers to the question: How do visualization techniques influence reading behavior? We compare plain text to that marked with highlights, icons, and word-sized data visualizations. We assess quantitative metrics (eye movement, completion time, error rate) and subjective feedback (personal preference and ratings). The results indicate that visualization techniques, especially in the first experiment, show promising trends for improved reading behavior. The results also show the need for further research to make reading more effective and inform suggestions for future studies."
"How Deep Is Your Gaze? Leveraging Distance in Image-Based Gaze Analysis.","2024","ETRA","Maurice Koch, Nelusa Pathmanathan, Daniel Weiskopf, Kuno Kurzhals","Conference and Workshop Papers","https://dblp.org/rec/conf/etra/KochPWK24","Image thumbnails are a valuable data source for fixation filtering, scanpath classification, and visualization of eye tracking data. They are typically extracted with a constant size, approximating the foveated area. As a consequence, the focused area of interest in the scene becomes less prominent in the thumbnail with increasing distance, affecting image-based analysis techniques. In this work, we propose depth-adaptive thumbnails, a method for varying image size according to the eye-to-object distance. Adjusting the visual angle relative to the distance leads to a zoom effect on the focused area. We evaluate our approach on recordings in augmented reality, investigating the similarity of thumbnails and scanpaths. Our quantitative findings suggest that considering the eye-to-object distance improves the quality of data analysis and visualization. We demonstrate the utility of depth-adaptive thumbnails for applications in scanpath comparison and visualization."
"NMF-Based Analysis of Mobile Eye-Tracking Data.","2024","ETRA","Daniel Klötzl, Tim Krake, Frank Heyen, Michael Becher, Maurice Koch, Daniel Weiskopf, Kuno Kurzhals","Conference and Workshop Papers","https://dblp.org/rec/conf/etra/KlotzlKHBKWK24","The depiction of scanpaths from mobile eye-tracking recordings by thumbnails from the stimulus allows the application of visual computing to detect areas of interest in an unsupervised way. We suggest using nonnegative matrix factorization (NMF) to identify such areas in stimuli. For a user-defined integer k, NMF produces an explainable decomposition into k components, each consisting of a spatial representation associated with a temporal indicator. In the context of multiple eye-tracking recordings, this leads to k spatial representations, where the temporal indicator highlights the appearance within recordings. The choice of k provides an opportunity to control the refinement of the decomposition, i.e., the number of areas to detect. We combine our NMF-based approach with visualization techniques to enable an exploratory analysis of multiple recordings. Finally, we demonstrate the usefulness of our approach with mobile eye-tracking data of an art gallery."
"Out-of-Core Dimensionality Reduction for Large Data via Out-of-Sample Extensions.","2024","CoRR","Luca Reichmann, David Hägele, Daniel Weiskopf","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2408-04129","Dimensionality reduction (DR) is a well-established approach for the visualization of high-dimensional data sets. While DR methods are often applied to typical DR benchmark data sets in the literature, they might suffer from high runtime complexity and memory requirements, making them unsuitable for large data visualization especially in environments outside of high-performance computing. To perform DR on large data sets, we propose the use of out-of-sample extensions. Such extensions allow inserting new data into existing projections, which we leverage to iteratively project data into a reference projection that consists only of a small manageable subset. This process makes it possible to perform DR out-of-core on large data, which would otherwise not be possible due to memory and runtime limitations. For metric multidimensional scaling (MDS), we contribute an implementation with out-of-sample projection capability since typical software libraries do not support it. We provide an evaluation of the projection quality of five common DR algorithms (MDS, PCA, t-SNE, UMAP, and autoencoders) using quality metrics from the literature and analyze the trade-off between the size of the reference set and projection quality. The runtime behavior of the algorithms is also quantified with respect to reference set size, out-of-sample batch size, and dimensionality of the data sets. Furthermore, we compare the out-of-sample approach to other recently introduced DR methods, such as PaCMAP and TriMAP, which claim to handle larger data sets than traditional approaches. To showcase the usefulness of DR on this large scale, we contribute a use case where we analyze ensembles of streamlines amounting to one billion projected instances."
"STEP: Sequence of time-aligned edge plots.","2024","Inf. Vis.","Moataz Abdelaal, Fabian Kannenberg, Antoine Lhuillier, Marcel Hlawatsch, Achim Menges, Daniel Weiskopf","Journal Articles","https://dblp.org/rec/journals/ivs/AbdelaalKLHMW24","We present sequence of time-aligned edge plots (STEP): a sequence- and edge-scalable visualization of dynamic networks and, more broadly, graph ensembles. We construct the graph sequence by ordering the individual graphs based on specific criteria, such as time for dynamic networks. To achieve scalability with respect to long sequences, we partition the sequence into equal-sized subsequences. Each subsequence is represented by a horizontal axis placed between two vertical axes. The horizontal axis depicts the order within the subsequence, while the two vertical axes depict the source and destination vertices. Edges within each subsequence are depicted as segmented lines extending from the source vertices on the left to the destination vertices on the right throughout the entire subsequence, and only the segments corresponding to the sequence members where the edges occur are drawn. By partitioning the sequence, STEP provides an overview of the graphs’ structural changes and avoids aspect ratio distortion. We showcase the utility of STEP for two realistic datasets. Additionally, we evaluate our approach by qualitatively comparing it against three state-of-the-art techniques using synthetic graphs with varying complexities. Furthermore, we evaluate the generalizability of STEP by applying it to a graph ensemble dataset from the architecture domain."
"Scalability in Visualization.","2024","IEEE Trans. Vis. Comput. Graph.","Gaëlle Richer, Alexis Pister, Moataz Abdelaal, Jean-Daniel Fekete, Michael Sedlmair, Daniel Weiskopf","Journal Articles","https://dblp.org/rec/journals/tvcg/RicherPAFSW24","We introduce a conceptual model for scalability designed for visualization research. With this model, we systematically analyze over 120 visualization publications from 1990 to 2020 to characterize the different notions of scalability in these works. While many article have addressed scalability issues, our survey identifies a lack of consistency in the use of the term in the visualization research community. We address this issue by introducing a consistent terminology meant to help visualization researchers better characterize the scalability aspects in their research. It also helps in providing multiple methods for supporting the claim that a work is “scalable.” Our model is centered around an effort function with inputs and outputs. The inputs are the problem size and resources, whereas the outputs are the actual efforts, for instance, in terms of computational run time or visual clutter. We select representative examples to illustrate different approaches and facets of what scalability can mean in visualization literature. Finally, targeting the diverse crowd of visualization researchers without a scalability tradition, we provide a set of recommendations for how scalability can be presented in a clear and consistent way to improve fair comparison between visualization techniques and systems and foster reproducibility."
"Toward reciprocal feedback between computational design, engineering, and fabrication to co-design coreless filament-wound structures.","2024","J. Comput. Des. Eng.","Fabian Kannenberg, Christoph Zechmeister, Marta Gil pérez, Yanan Guo, Xiliu Yang, David Forster, Sebastian Hügle, Pascal Mindermann, Moataz Abdelaal, Laura Balangé, Volker Schwieger, Daniel Weiskopf, Götz T. Gresser, Peter Middendorf, Manfred Bischoff, Jan Knippers, Achim Menges","Journal Articles","https://dblp.org/rec/journals/jcde/KannenbergZpGYFHMABSWGM24","Abstract
               Fiber-reinforced composites offer innovative solutions for architectural applications with high strength and low weight. Coreless filament winding extends industrial processes, reduces formwork, and allows for tailoring of fiber layups to specific requirements. A previously developed computational co-design framework for coreless filament winding is extended toward the integration of reciprocal design feedback to maximize design flexibility and inform design decisions throughout the process. A multi-scalar design representation is introduced, representing fiber structures at different levels of detail to generate feedback between computational design, engineering, and fabrication. Design methods for global, component, and material systems are outlined and feedback generation is explained. Structural and fabrication feedback are classified, and their integration is described in detail. This paper demonstrates how reciprocal feedback allows for co-evolution of domains of expertise and extends the existing co-design framework toward design problems. The developed methods are shown in two case studies at a global and component scale."
"Uncertainty-Aware Seasonal-Trend Decomposition Based on Loess - Supplemental Material.","2024","DaRUS","Tim Krake, Daniel Klötzl, David Hägele, Daniel Weiskopf","Data and Artifacts","https://dblp.org/rec/data/10/KrakeKHW24",""
"Visual Analysis of Multi-outcome Causal Graphs.","2024","CoRR","Mengjie Fan, Jinlu Yu, Daniel Weiskopf, Nan Cao 0001, Huai-Yu Wang, Liang Zhou 0001","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2408-02679","We introduce a visual analysis method for multiple causal graphs with different outcome variables, namely, multi-outcome causal graphs. Multi-outcome causal graphs are important in healthcare for understanding multimorbidity and comorbidity. To support the visual analysis, we collaborated with medical experts to devise two comparative visualization techniques at different stages of the analysis process. First, a progressive visualization method is proposed for comparing multiple state-of-the-art causal discovery algorithms. The method can handle mixed-type datasets comprising both continuous and categorical variables and assist in the creation of a fine-tuned causal graph of a single outcome. Second, a comparative graph layout technique and specialized visual encodings are devised for the quick comparison of multiple causal graphs. In our visual analysis approach, analysts start by building individual causal graphs for each outcome variable, and then, multi-outcome causal graphs are generated and visualized with our comparative technique for analyzing differences and commonalities of these causal graphs. Evaluation includes quantitative measurements on benchmark datasets, a case study with a medical expert, and expert user studies with real-world health research data."
"Visual analysis of fitness landscapes in architectural design optimization.","2024","Vis. Comput.","Moataz Abdelaal, Marcel Galuschka, Max Zorn, Fabian Kannenberg, Achim Menges, Thomas Wortmann, Daniel Weiskopf, Kuno Kurzhals","Journal Articles","https://dblp.org/rec/journals/vc/AbdelaalGZKMWWK24","AbstractIn architectural design optimization, fitness landscapes are used to visualize design space parameters in relation to one or more objective functions for which they are being optimized. In our design study with domain experts, we developed a visual analytics framework for exploring and analyzing fitness landscapes spanning data, projection, and visualization layers. Within the data layer, we employ two surrogate models and three sampling strategies to efficiently generate a wide array of landscapes. On the projection layer, we use star coordinates and UMAP as two alternative methods for obtaining a 2D embedding of the design space. Our interactive user interface can visualize fitness landscapes as a continuous density map or a discrete glyph-based map. We investigate the influence of surrogate models and sampling strategies on the resulting fitness landscapes in a parameter study. Additionally, we present findings from a user study (N = 12), revealing how experts’ preferences regarding projection methods and visual representations may be influenced by their level of expertise, characteristics of the techniques, and the specific task at hand. Furthermore, we demonstrate the usability and usefulness of our framework by a case study from the architecture domain, involving one domain expert."
"Which Experimental Design is Better Suited for VQA Tasks? Eye Tracking Study on Cognitive Load, Performance, and Gaze Allocations.","2024","CoRR","Sita Vriend, Sandeep Vidyapu, Amer Rama, Kun-Ting Chen, Daniel Weiskopf","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2404-04036","We conducted an eye-tracking user study with 13 participants to investigate the influence of stimulus-question ordering and question modality on participants using visual question-answering (VQA) tasks. We examined cognitive load, task performance, and gaze allocations across five distinct experimental designs, aiming to identify setups that minimize the cognitive burden on participants. The collected performance and gaze data were analyzed using quantitative and qualitative methods. Our results indicate a significant impact of stimulus-question ordering on cognitive load and task performance, as well as a noteworthy effect of question modality on task performance. These findings offer insights for the experimental design of controlled user studies in visualization research."
"Which Experimental Design is Better Suited for VQA Tasks?: Eye Tracking Study on Cognitive Load, Performance, and Gaze Allocations.","2024","ETRA","Sita Aukje Vriend, Sandeep Vidyapu, Amer Rama, Kun-Ting Chen, Daniel Weiskopf","Conference and Workshop Papers","https://dblp.org/rec/conf/etra/VriendVRCW24","We conducted an eye-tracking user study with 13 participants to investigate the influence of stimulus-question ordering and question modality on participants using visual question-answering (VQA) tasks. We examined cognitive load, task performance, and gaze allocations across five distinct experimental designs, aiming to identify setups that minimize the cognitive burden on participants. The collected performance and gaze data were analyzed using quantitative and qualitative methods. Our results indicate a significant impact of stimulus-question ordering on cognitive load and task performance, as well as a noteworthy effect of question modality on task performance. These findings offer insights for the experimental design of controlled user studies in visualization research."
"Your visualisations are going places: Performance data for scientific visualisation on gaming consoles.","2024","DaRUS","Michael Becher, Christoph Müller 0001, Guido Reina, Daniel Weiskopf, Thomas Ertl","Data and Artifacts","https://dblp.org/rec/data/10/BecherMRWE24",""
"Comparative Evaluation of Bipartite, Node-Link, and Matrix-Based Network Representations.","2023","IEEE Trans. Vis. Comput. Graph.","Moataz Abdelaal, Nathan Daniel Schiele, Katrin Angerbauer, Kuno Kurzhals, Michael Sedlmair, Daniel Weiskopf","Journal Articles","https://dblp.org/rec/journals/tvcg/AbdelaalSAKSW23",""
"Constrained Dynamic Mode Decomposition.","2023","IEEE Trans. Vis. Comput. Graph.","Tim Krake, Daniel Klötzl, Bernhard Eberhardt, Daniel Weiskopf","Journal Articles","https://dblp.org/rec/journals/tvcg/KrakeKEW23","Frequency-based decomposition of time series data is used in many visualization applications. Most of these decomposition methods (such as Fourier transform or singular spectrum analysis) only provide interaction via pre- and post-processing, but no means to influence the core algorithm. A method that also belongs to this class is Dynamic Mode Decomposition (DMD), a spectral decomposition method that extracts spatio-temporal patterns from data. In this paper, we incorporate frequency-based constraints into DMD for an adaptive decomposition that leads to user-controllable visualizations, allowing analysts to include their knowledge into the process. To accomplish this, we derive an equivalent reformulation of DMD that implicitly provides access to the eigenvalues (and therefore to the frequencies) identified by DMD. By utilizing a constrained minimization problem customized to DMD, we can guarantee the existence of desired frequencies by minimal changes to DMD. We complement this core approach by additional techniques for constrained DMD to facilitate explorative visualization and investigation of time series data. With several examples, we demonstrate the usefulness of constrained DMD and compare it to conventional frequency-based decomposition methods."
"Relaxed Dot Plots: Faithful Visualization of Samples and Their Distribution.","2023","IEEE Trans. Vis. Comput. Graph.","Nils Rodrigues, Christoph Schulz 0001, Sören Döring, Daniel Baumgartner, Tim Krake, Daniel Weiskopf","Journal Articles","https://dblp.org/rec/journals/tvcg/RodriguesSDBKW23","We introduce relaxed dot plots as an improvement of nonlinear dot plots for unit visualization. Our plots produce more faithful data representations and reduce moiré effects. Their contour is based on a customized kernel frequency estimation to match the shape of the distribution of underlying data values. Previous nonlinear layouts introduce column-centric nonlinear scaling of dot diameters for visualization of high-dynamic-range data with high peaks. We provide a mathematical approach to convert that column-centric scaling to our smooth envelope shape. This formalism allows us to use linear, root, and logarithmic scaling to find ideal dot sizes. Our method iteratively relaxes the dot layout for more correct and aesthetically pleasing results. To achieve this, we modified Lloyd's algorithm with additional constraints and heuristics. We evaluate the layouts of relaxed dot plots against a previously existing nonlinear variant and show that our algorithm produces less error regarding the underlying data while establishing the blue noise property that works against moiré effects. Further, we analyze the readability of our relaxed plots in three crowd-sourced experiments. The results indicate that our proposed technique surpasses traditional dot plots."
"Bridging Quantitative and Qualitative Methods for Visualization Research: A Data/Semantics Perspective in Light of Advanced AI.","2024","CoRR","Daniel Weiskopf","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2409-07250","This paper revisits the role of quantitative and qualitative methods in visualization research in the context of advancements in artificial intelligence (AI). The focus is on how we can bridge between the different methods in an integrated process of analyzing user study data. To this end, a process model of - potentially iterated - semantic enrichment and transformation of data is proposed. This joint perspective of data and semantics facilitates the integration of quantitative and qualitative methods. The model is motivated by examples of own prior work, especially in the area of eye tracking user studies and coding data-rich observations. Finally, there is a discussion of open issues and research opportunities in the interplay between AI, human analyst, and qualitative and quantitative methods for visualization research."
"Testing the Test: Observations When Assessing Visualization Literacy of Domain Experts.","2024","CoRR","Seyda Öney, Moataz Abdelaal, Kuno Kurzhals, Paul Betz, Cordula Kropp, Daniel Weiskopf","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2409-08101","AbstractEnglish teachers' assessment literacy has always been considered as an important factor in their performance. However, no instrument has ever been developed to assess this construct among Iranian EFL teachers. To fill this gap, in the first phase of the present study a theoretical framework for the main four components of teacher assessment literacy, named validity, reliability, interpretability of the results, and efficiency, was developed through extensive review of the related literature and conducting interviews with PhD candidates of TEFL. In the second phase, a questionnaire was developed and piloted with 150 participants who took part in the study through the rules of convenience sampling. More specifically, the 30 items of the newly-developed “ELTs’ Assessment Literacy” questionnaire were subjected to factor analysis which revealed the presence of all the four components consisting of different number of items. These phases led to the development of a questionnaire with four components and 25 items on the basis of a five point Likert scale that measured: (1) “Validity” including six items, (2) “Reliability” including ten items, (3) “Interpretability of the Results” including eight item, and (4) “Efficiency” including five items. The findings of this study may shed lights on this subject and help researchers and teaching practitioners assess EFL teachers’ assessment literacy and make principled decisions as far as assessment is concerned."
"UADAPy: An Uncertainty-Aware Visualization and Analysis Toolbox.","2024","CoRR","Patrick Paetzold, David Hägele, Marina Evers, Daniel Weiskopf, Oliver Deussen","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2409-10217",""
"Visual Compositional Data Analytics for Spatial Transcriptomics.","2024","CoRR","David Hägele, Yuxuan Tang, Daniel Weiskopf","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2409-07306","AbstractSpatial transcriptomics (ST) technologies are powerful tools to illustrate the spatial hierarchy and heterogeneity of tissues with the lens of multiplexed gene readouts. However, ST technologies generate sequence data rather than images, preventing intuitive examination of the cellular contexture of tissues. Moreover, the inherent sparsity of ST data caused by molecular crowdedness and sequencing dropouts poses great challenges to accurate and clear visualization. In this study, we introduce RedeViz, a toolkit crafted for enhancing and visualizing subcellular-resolution ST data. RedeViz applies a pixel-level enhancement strategy, visualizes ST data in automatic or customized manners, and can display the cellular and genic spatial patterns with effects akin to HE staining. Strict evaluations confirm that RedeViz fits a wide range of ST platforms, including Xenium, Visium HD, MERFISH, CosMx, Stereoseq, as well as spatial proteomic platforms like CODEX. The impressive performance of RedeViz across various scales from cell-, tissue-, organ-, to organism-levels brings us a universal “What You See Is What You Get” framework for visual analysis of ST data."
"""Research Data Curation in Visualization : Position Paper"" (Data).","2023","DaRUS","Dimitar Garkov, Christoph Müller 0001, Matthias Braun 0005, Daniel Weiskopf, Falk Schreiber","Data and Artifacts","https://dblp.org/rec/data/10/GarkovMBWS23a",""
"Accelerated 2D visualization using adaptive resolution scaling and temporal reconstruction.","2023","J. Vis.","Michael Becher, Moritz Heinemann, Thomas Marmann, Guido Reina, Daniel Weiskopf, Thomas Ertl","Journal Articles","https://dblp.org/rec/journals/jvis/BecherHMRWE23","Abstract
                Data visualization relies on efficient rendering to allow users to interactively explore and understand their data. However, achieving interactive frame rates is often challenging, especially for high-resolution displays or large datasets. In computer graphics, several methods temporally reconstruct full-resolution images from multiple consecutive lower-resolution frames. Besides providing temporal image stability, they amortize the rendering costs over multiple frames and thus improve the minimum frame rate. We present a method that adopts this idea to accelerate 2D information visualization, without requiring any changes to the rendering itself. By exploiting properties of orthographic projection, our method significantly improves rendering performance while minimizing the loss of image quality during camera manipulation. For static scenes, it quickly converges to the full-resolution image. We discuss the characteristics and different modes of our method concerning rendering performance and image quality and the corresponding trade-offs. To improve ease of use, we provide automatic resolution scaling in our method to adapt to user-defined target frame rate. Finally, we present extensive rendering benchmarks to examine real-world performance for examples of parallel coordinates and scatterplot matrix visualizations, and discuss appropriate application scenarios and contraindications for usage.
              
                Graphical Abstract"
"Angle-uniform parallel coordinates.","2023","Comput. Vis. Media","Kaiyi Zhang 0003, Liang Zhou 0001, Lu Chen, Shitong He, Daniel Weiskopf, Yunhai Wang","Journal Articles","https://dblp.org/rec/journals/cvm/ZhangZCHWW23","AbstractWe present angle-uniform parallel coordinates, a data-independent technique that deforms the image plane of parallel coordinates so that the angles of linear relationships between two variables are linearly mapped along the horizontal axis of the parallel coordinates plot. Despite being a common method for visualizing multidimensional data, parallel coordinates are ineffective for revealing positive correlations since the associated parallel coordinates points of such structures may be located at infinity in the image plane and the asymmetric encoding of negative and positive correlations may lead to unreliable estimations. To address this issue, we introduce a transformation that bounds all points horizontally using an angle-uniform mapping and shrinks them vertically in a structure-preserving fashion; polygonal lines become smooth curves and a symmetric representation of data correlations is achieved. We further propose a combined subsampling and density visualization approach to reduce visual clutter caused by overdrawing. Our method enables accurate visual pattern interpretation of data correlations, and its data-independent nature makes it applicable to all multidimensional datasets. The usefulness of our method is demonstrated using examples of synthetic and real-world datasets."
"Been There, Seen That: Visualization of Movement and 3D Eye Tracking Data from Real-World Environments.","2023","Comput. Graph. Forum","Nelusa Pathmanathan, Seyda Öney, Michael Becher, Michael Sedlmair, Daniel Weiskopf, Kuno Kurzhals","Journal Articles","https://dblp.org/rec/journals/cgf/PathmanathanOBSWK23","The distribution of visual attention can be evaluated using eye tracking, providing valuable insights into usability issues and interaction patterns. However, when used in real, augmented, and collaborative environments, new challenges arise that go beyond desktop scenarios and purely virtual environments. Toward addressing these challenges, we present a visualization technique that provides complementary views on the movement and eye tracking data recorded from multiple people in real‐world environments. Our method is based on a space‐time cube visualization and a linked 3D replay of recorded data. We showcase our approach with an experiment that examines how people investigate an artwork collection. The visualization provides insights into how people moved and inspected individual pictures in their spatial context over time. In contrast to existing methods, this analysis is possible for multiple participants without extensive annotation of areas of interest. Our technique was evaluated with a think‐aloud experiment to investigate analysis strategies and an interview with domain experts to examine the applicability in other research fields."
"Gazealytics: A Unified and Flexible Visual Toolkit for Exploratory and Comparative Gaze Analysis.","2023","ETRA","Kun-Ting Chen, Arnaud Prouzeau, Joshua Langmead, Ryan T. Whitelock-Jones, Lawrence Lee, Tim Dwyer, Christophe Hurter, Daniel Weiskopf, Sarah Goodwin","Conference and Workshop Papers","https://dblp.org/rec/conf/etra/ChenPLWLDHWG23","We present a novel, web-based visual eye-tracking analytics tool called Gazealytics. Our open-source toolkit features a unified combination of gaze analytics features that support flexible exploratory analysis, along with annotation of areas of interest (AOI) and filter options based on multiple criteria to visually analyse eye tracking data across time and space. Gazealytics features coordinated views unifying spatiotemporal exploration of fixations and scanpaths for various analytical tasks. A novel matrix representation allows analysis of relationships between such spatial or temporal features. Data can be grouped across samples, user-defined AOIs or time windows of interest (TWIs) to support aggregate or filtered analysis of gaze activity. This approach exceeds the capabilities of existing systems by supporting flexible comparison between and within subjects, hypothesis generation, data analysis and communication of insights. We demonstrate in a walkthrough that Gazealytics supports multiple types of eye tracking datasets and analytical tasks."
"Group Diagrams for simplified representation of scanpaths.","2023","J. Vis.","Peter Schäfer, Nils Rodrigues, Daniel Weiskopf, Sabine Storandt","Journal Articles","https://dblp.org/rec/journals/jvis/SchaferRWS23","Abstract
                We instrument Group Diagrams (GDs) to reduce clutter in sets of eye-tracking scanpaths. Group Diagrams consist of trajectory subsets that cover, or represent, the whole set of trajectories with respect to some distance measure and an adjustable distance threshold. The original GDs allow for an application of various distance measures. We implement the GD framework and evaluate it on scanpaths that were collected by a former user study on public transit maps. We find that the Fréchet distance is the most appropriate measure to get meaningful results, yet it is flexible enough to cover outliers. We discuss several implementation-specific challenges and improve the scalability of the algorithm. To evaluate our results, we conducted a qualitative study with a group of eye-tracking experts. Finally, we note that our enhancements are also beneficial within the original problem setting, suggesting that our approach might be applicable to various types of input data.
              
                Graphical abstract
                Eye tracking on a public transit map of Warsaw. Input scanpaths (left), and simplified Group Diagram (right)."
"Model Parameters and Evaluation Data for our Visual Analysis System for Scene-Graph-Based Visual Question Answering.","2023","DaRUS","Noel Schäfer, Pascal Tilli, Tanja Munz-Körner, Sebastian Künzel, Sandeep Vidyapu, Ngoc Thang Vu, Daniel Weiskopf","Data and Artifacts","https://dblp.org/rec/data/10/SchaferTMKVVW23a",""
"Multi-attribute Visualization and Improved Depth Perception for the Interactive Analysis of 3D Truss Structures.","2023","EuroVis","Michael Becher, Anja Groß, Peter Werner, Mathias Maierhofer, Guido Reina, Thomas Ertl, Achim Menges, Daniel Weiskopf","Conference and Workshop Papers","https://dblp.org/rec/conf/vissym/BecherGWMREMW23",""
"Reading Strategies for Graph Visualizations that Wrap Around in Torus Topology.","2023","ETRA","Kun-Ting Chen, Quynh Quang Ngo, Kuno Kurzhals, Kim Marriott, Tim Dwyer, Michael Sedlmair, Daniel Weiskopf","Conference and Workshop Papers","https://dblp.org/rec/conf/etra/ChenNKMDSW23","We investigate reading strategies for node-link diagrams that wrap around the boundaries in a flattened torus topology by examining eye tracking data recorded in a previous controlled study. Prior work showed that torus drawing affords greater flexibility in clutter reduction than traditional node-link representations, but impedes link-and-path exploration tasks, while repeating tiles around boundaries aids comprehension. However, it remains unclear what strategies users apply in different wrapping settings. This is important for design implications for future work on more effective wrapped visualizations for network applications, and cyclic data that could benefit from wrapping. We perform visual-exploratory data analysis of gaze data, and conduct statistical tests derived from the patterns identified. Results show distinguishable gaze behaviors, with more visual glances and transitions between areas of interest in the non-replicated layout. Full-context has more successful visual searches than partial-context, but the gaze allocation indicates that the layout could be more space-efficient."
"Replication Data for: Been There, Seen That: Visualization of Movement and 3D Eye Tracking Data from Real-World Environments.","2023","DaRUS","Nelusa Pathmanathan, Seyda Öney, Michael Becher, Michael Sedlmair, Daniel Weiskopf, Kuno Kurzhals","Data and Artifacts","https://dblp.org/rec/data/10/PathmanathanOBSWK23a","AbstractThe distribution of visual attention can be evaluated using eye tracking, providing valuable insights into usability issues and interaction patterns. However, when used in real, augmented, and collaborative environments, new challenges arise that go beyond desktop scenarios and purely virtual environments. Toward addressing these challenges, we present a visualization technique that provides complementary views on the movement and eye tracking data recorded from multiple people in real‐world environments. Our method is based on a space‐time cube visualization and a linked 3D replay of recorded data. We showcase our approach with an experiment that examines how people investigate an artwork collection. The visualization provides insights into how people moved and inspected individual pictures in their spatial context over time. In contrast to existing methods, this analysis is possible for multiple participants without extensive annotation of areas of interest. Our technique was evaluated with a think‐aloud experiment to investigate analysis strategies and an interview with domain experts to examine the applicability in other research fields."
"Replication Data for: Visual Gaze Labeling for Augmented Reality Studies.","2023","DaRUS","Seyda Öney, Nelusa Pathmanathan, Michael Becher, Michael Sedlmair, Daniel Weiskopf, Kuno Kurzhals","Data and Artifacts","https://dblp.org/rec/data/10/OneyPBSWK23a","Augmented Reality (AR) provides new ways for situated visualization and human‐computer interaction in physical environments. Current evaluation procedures for AR applications rely primarily on questionnaires and interviews, providing qualitative means to assess usability and task solution strategies. Eye tracking extends these existing evaluation methodologies by providing indicators for visual attention to virtual and real elements in the environment. However, the analysis of viewing behavior, especially the comparison of multiple participants, is difficult to achieve in AR. Specifically, the definition of areas of interest (AOIs), which is often a prerequisite for such analysis, is cumbersome and tedious with existing approaches. To address this issue, we present a new visualization approach to define AOIs, label fixations, and investigate the resulting annotated scanpaths. Our approach utilizes automatic annotation of gaze on virtual objects and an image‐based approach that also considers spatial context for the manual annotation of objects in the real world. Our results show, that with our approach, eye tracking data from AR scenes can be annotated and analyzed flexibly with respect to data aspects and annotation strategies."
"Supplemental Material for ""Visual-Explainable AI: The Use Case of Language Models"".","2023","DaRUS","Tanja Munz-Körner, Sebastian Künzel, Daniel Weiskopf","Data and Artifacts","https://dblp.org/rec/data/10/MunzKornerKW23",""
"Uncertainty-Aware Multidimensional Scaling.","2023","IEEE Trans. Vis. Comput. Graph.","David Hägele, Tim Krake, Daniel Weiskopf","Journal Articles","https://dblp.org/rec/journals/tvcg/HageleKW23","We present an extension of multidimensional scaling (MDS) to uncertain data, facilitating uncertainty visualization of multidimensional data. Our approach uses local projection operators that map high-dimensional random vectors to low-dimensional space to formulate a generalized stress. In this way, our generic model supports arbitrary distributions and various stress types. We use our uncertainty-aware multidimensional scaling (UAMDS) concept to derive a formulation for the case of normally distributed random vectors and a squared stress. The resulting minimization problem is numerically solved via gradient descent. We complement UAMDS by additional visualization techniques that address the sensitivity and trustworthiness of dimensionality reduction under uncertainty. With several examples, we demonstrate the usefulness of our approach and the importance of uncertainty-aware techniques."
"Visual Analysis System for Scene-Graph-Based Visual Question Answering.","2023","DaRUS","Noel Schäfer, Pascal Tilli, Tanja Munz-Körner, Sebastian Künzel, Sandeep Vidyapu, Ngoc Thang Vu, Daniel Weiskopf","Data and Artifacts","https://dblp.org/rec/data/10/SchaferTMKVVW23","Scene-graph-based Visual Question Answering (VQA) has emerged as a burgeoning field in Deep Learning research, with a growing demand for robust and interpretable VQA systems. In this paper, we present a novel visual analysis approach that addresses two critical objectives in VQA: identifying and correcting prediction issues and providing insights into model decision-making processes through visualizing internal information. Our approach builds on the GraphVQA framework, which uses graph neural networks to process scene graphs representing images and which was trained on the widely-used GQA dataset. Our analysis tool aims at users familiar with the basics of graph-based VQA. By leveraging query-based scene analysis and visualization of crucial internal states, we are able to detect and pinpoint reasons for inaccurate predictions, facilitating model refinement and dataset curation. Identifying expressive internal states is a challenge. Through rigorous computer-based evaluations and presentation of a use case, we demonstrate the effectiveness of our analysis tool and model state visualization."
"Visual Analysis of Scene-Graph-Based Visual Question Answering.","2023","VINCI","Noel Schäfer, Sebastian Künzel, Tanja Munz-Körner, Pascal Tilli, Sandeep Vidyapu, Ngoc Thang Vu, Daniel Weiskopf","Conference and Workshop Papers","https://dblp.org/rec/conf/vinci/SchaferKMTVVW23","Scene-graph-based Visual Question Answering (VQA) has emerged as a burgeoning field in Deep Learning research, with a growing demand for robust and interpretable VQA systems. In this paper, we present a novel visual analysis approach that addresses two critical objectives in VQA: identifying and correcting prediction issues and providing insights into model decision-making processes through visualizing internal information. Our approach builds on the GraphVQA framework, which uses graph neural networks to process scene graphs representing images and which was trained on the widely-used GQA dataset. Our analysis tool aims at users familiar with the basics of graph-based VQA. By leveraging query-based scene analysis and visualization of crucial internal states, we are able to detect and pinpoint reasons for inaccurate predictions, facilitating model refinement and dataset curation. Identifying expressive internal states is a challenge. Through rigorous computer-based evaluations and presentation of a use case, we demonstrate the effectiveness of our analysis tool and model state visualization."
"Visual Gaze Labeling for Augmented Reality Studies.","2023","Comput. Graph. Forum","Seyda Öney, Nelusa Pathmanathan, Michael Becher, Michael Sedlmair, Daniel Weiskopf, Kuno Kurzhals","Journal Articles","https://dblp.org/rec/journals/cgf/OneyPBSWK23","Augmented Reality (AR) provides new ways for situated visualization and human‐computer interaction in physical environments. Current evaluation procedures for AR applications rely primarily on questionnaires and interviews, providing qualitative means to assess usability and task solution strategies. Eye tracking extends these existing evaluation methodologies by providing indicators for visual attention to virtual and real elements in the environment. However, the analysis of viewing behavior, especially the comparison of multiple participants, is difficult to achieve in AR. Specifically, the definition of areas of interest (AOIs), which is often a prerequisite for such analysis, is cumbersome and tedious with existing approaches. To address this issue, we present a new visualization approach to define AOIs, label fixations, and investigate the resulting annotated scanpaths. Our approach utilizes automatic annotation of gaze on virtual objects and an image‐based approach that also considers spatial context for the manual annotation of objects in the real world. Our results show, that with our approach, eye tracking data from AR scenes can be annotated and analyzed flexibly with respect to data aspects and annotation strategies."
"Datamator: An Intelligent Authoring Tool for Creating Datamations via Data Query Decomposition.","2023","CoRR","Yi Guo, Nan Cao 0001, Ligan Cai, Yanqiu Wu 0001, Daniel Weiskopf, Danqing Shi, Qing Chen 0001","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2304-03126","Datamation is designed to animate an analysis pipeline step by step, which is an intuitive and effective way to interpret the results from data analysis. However, creating a datamation is not easy. A qualified datamation needs to not only provide a correct analysis result but also ensure that the data flow and animation are coherent. Existing animation authoring tools focus on either leveraging algorithms to automatically generate an animation based on user-provided charts or building graphical user interfaces to provide a programming-free authoring environment for users. None of them are able to help users translate an analysis task into a series of data operations to form an analysis pipeline and visualize them as a datamation. To fill this gap, we introduce Datamator, an intelligent authoring tool developed to support datamation design and generation. It leverages a novel data query decomposition model to allow users to generate an initial datamation by simply inputting a data query in natural language. The initial datamation can be refined via rich interactions and a feedback mechanism is utilized to update the decomposition model based on user knowledge and preferences. Our system produces an animated sequence of visualizations driven by a set of low-level data actions. It supports unit visualizations, which provide a mapping from each data item to a unique visual mark. We demonstrate the effectiveness of Datamator via a series of evaluations including case studies, performance validation, and a controlled user study."
"Supplemental Material for ""Which Experimental Design is Better Suited for VQA Tasks? - Eye Tracking Study on Cognitive Load, Performance, and Gaze Allocations"".","2023","DaRUS","Sita Vriend, Sandeep Vidyapu, Amer Rama, Kun-Ting Chen, Daniel Weiskopf","Data and Artifacts","https://dblp.org/rec/data/10/VriendVRCW23",""
"Urania: Visualizing Data Analysis Pipelines for Natural Language-Based Data Exploration.","2023","CoRR","Yi Guo, Nan Cao 0001, Xiaoyu Qi, Haoyang Li, Danqing Shi, Jing Zhang, Qing Chen 0001, Daniel Weiskopf","Informal and Other Publications","https://dblp.org/rec/journals/corr/abs-2306-07760",""
